{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d91ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d8e55dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rutas\n",
    "PATH_GLOBAL = os.getcwd()\n",
    "PATH = os.path.join(PATH_GLOBAL, \"datasets\")\n",
    "PATH_JSON = Path(os.path.join(PATH, \"fallos_json\"))\n",
    "PATH_ARTICULOS_CITADOS = Path(os.path.join(PATH, \"articulos_citados_hard\"))\n",
    "\n",
    "# Ejecutar extracci√≥n (puedes modificar los patrones regex despu√©s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687136ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cited_articles_and_laws(json_dir: str, output_dir: str, regex_patterns: list = None):\n",
    "    \"\"\"\n",
    "    Extrae art√≠culos y leyes citados de cada subsecci√≥n de CONTENIDO en los JSONs.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directorio con los JSONs originales (ej: datasets/fallos_json)\n",
    "        output_dir: Directorio de salida (ej: datasets/articulos_citados_hard)\n",
    "        regex_patterns: Lista de patrones regex para extraer citas (opcional)\n",
    "    \"\"\"\n",
    "    json_root = Path(json_dir).resolve()\n",
    "    output_root = Path(output_dir).resolve()\n",
    "    output_root.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Patrones regex mejorados\n",
    "    if regex_patterns is None:\n",
    "        regex_patterns = [\n",
    "            # Art√≠culos con diferentes formatos\n",
    "            r'-?arts?\\.\\s*(\\d+(?:¬∫|¬∞)?)(?:\\s*[,y]\\s*(\\d+(?:¬∫|¬∞)?))*',  # arts. 3, 14, 29 y 94 o -arts. 1¬∫ y 4¬∫\n",
    "            r'Art(?:√≠culo)?s?\\.\\s*(\\d+(?:¬∫|¬∞)?)(?:\\s*[,y]\\s*(\\d+(?:¬∫|¬∞)?))*',  # Art. 28, Art√≠culo 45\n",
    "            r'del\\s+art\\.?\\s*(\\d+(?:¬∫|¬∞)?)',  # del art.114\n",
    "            r'art√≠culos?\\s+(\\d+(?:¬∫|¬∞)?)(?:\\s*[,y]\\s*(\\d+(?:¬∫|¬∞)?))*',  # art√≠culo 123 y 456\n",
    "            \n",
    "            # Leyes con diferentes formatos\n",
    "            r'ley\\s+n?¬∫?\\s*(\\d+(?:/\\d+)?)',  # ley 7046, ley n¬∫ 5678/90\n",
    "            r'leyes?\\s+n?¬∫?\\s*(\\d+(?:/\\d+)?)(?:\\s*[,y]\\s*(\\d+(?:/\\d+)?))*',  # leyes 123 y 456\n",
    "            \n",
    "            # N√∫meros standalone despu√©s de menciones de art√≠culos (para capturar secuencias)\n",
    "            r'(?:arts?\\.|art√≠culos?|Art\\.)\\s*[^\\d]*(\\d+(?:¬∫|¬∞)?(?:\\s*[,y]\\s*\\d+(?:¬∫|¬∞)?)*(?:\\s*y\\s*\\d+(?:¬∫|¬∞)?)?)',\n",
    "        ]\n",
    "    \n",
    "    def extract_numbers_from_match(match_groups):\n",
    "        \"\"\"Extrae todos los n√∫meros de los grupos de una coincidencia regex\"\"\"\n",
    "        numbers = []\n",
    "        for group in match_groups:\n",
    "            if group:  # Si el grupo no es None\n",
    "                # Buscar todos los n√∫meros en el grupo\n",
    "                nums = re.findall(r'\\d+(?:¬∫|¬∞)?', group)\n",
    "                numbers.extend(nums)\n",
    "        return numbers\n",
    "    \n",
    "    def extract_articles_from_text(text):\n",
    "        \"\"\"Extrae art√≠culos de un texto usando m√∫ltiples estrategias\"\"\"\n",
    "        all_articles = set()  # Usar set para evitar duplicados\n",
    "        \n",
    "        # Estrategia 1: Patrones espec√≠ficos\n",
    "        for pattern in compiled_patterns:\n",
    "            matches = pattern.finditer(text)\n",
    "            for match in matches:\n",
    "                numbers = extract_numbers_from_match(match.groups())\n",
    "                all_articles.update(numbers)\n",
    "        \n",
    "        # Estrategia 2: Buscar secuencias espec√≠ficas como \"3, 14, 29, 30, 63, 64, 71 y 94\"\n",
    "        # Patr√≥n para capturar listas de n√∫meros despu√©s de \"arts.\" o similar\n",
    "        sequence_pattern = r'(?:-?arts?\\.|art√≠culos?|Art\\.)\\s*([0-9¬∫¬∞,\\s\\-y]+?)(?:\\s+de\\s+la\\s+ley|\\s+Ac\\.|\\.|\\s|$)'\n",
    "        seq_matches = re.finditer(sequence_pattern, text, re.IGNORECASE)\n",
    "        for match in seq_matches:\n",
    "            sequence = match.group(1)\n",
    "            # Extraer todos los n√∫meros de la secuencia\n",
    "            nums = re.findall(r'\\d+(?:¬∫|¬∞)?', sequence)\n",
    "            all_articles.update(nums)\n",
    "        \n",
    "        return list(all_articles)\n",
    "    \n",
    "    # Compilar patrones\n",
    "    compiled_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in regex_patterns]\n",
    "    \n",
    "    json_files = list(json_root.rglob(\"*.json\"))\n",
    "    if not json_files:\n",
    "        print(f\"No se encontraron JSONs en {json_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üîç Extrayendo citas de {len(json_files)} archivos JSON...\")\n",
    "    \n",
    "    for json_path in tqdm(json_files, desc=\"Extrayendo citas\"):\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)[0]  # Primer elemento de la lista\n",
    "            \n",
    "            # Crear estructura de salida\n",
    "            output_structure = {\n",
    "                \"INFORMACION\": data.get(\"INFORMACION\", {}),\n",
    "                \"CONTENIDO\": {}\n",
    "            }\n",
    "            \n",
    "            # Procesar cada subsecci√≥n de CONTENIDO\n",
    "            if 'CONTENIDO' in data:\n",
    "                for section_name, paragraphs in data['CONTENIDO'].items():\n",
    "                    cited_articles = []\n",
    "                    \n",
    "                    # Buscar citas en cada p√°rrafo de la subsecci√≥n\n",
    "                    for paragraph in paragraphs:\n",
    "                        if isinstance(paragraph, str):\n",
    "                            articles = extract_articles_from_text(paragraph)\n",
    "                            cited_articles.extend(articles)\n",
    "                    \n",
    "                    # Remover duplicados y ordenar\n",
    "                    cited_articles = sorted(list(set(cited_articles)))\n",
    "                    \n",
    "                    # Guardar lista de citas para esta subsecci√≥n\n",
    "                    output_structure[\"CONTENIDO\"][section_name] = cited_articles\n",
    "            \n",
    "            # Crear archivo de salida manteniendo estructura de carpetas\n",
    "            rel_path = json_path.relative_to(json_root)\n",
    "            output_path = output_root / rel_path\n",
    "            output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Guardar JSON con citas extra√≠das\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump([output_structure], f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error procesando {json_path}: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ Extracci√≥n completada. Archivos guardados en: {output_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1751bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extrayendo citas de 296 archivos JSON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrayendo citas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 296/296 [00:00<00:00, 860.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracci√≥n completada. Archivos guardados en: /Users/brunocr/Documents/UDESA/NLP/TP_NLP/datasets/articulos_citados_hard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_cited_articles_and_laws(PATH_JSON, PATH_ARTICULOS_CITADOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f13f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import AzureOpenAI\n",
    "from configs.credentials_config import API_KEY, ENDPOINT, MODEL, DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b161cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pydantic schemas\n",
    "class CitedLaw(BaseModel):\n",
    "    \"\"\"Schema for a cited law with its articles\"\"\"\n",
    "    number: str = Field(description=\"Law number (e.g., '7046', '123/90')\")\n",
    "    articles: List[str] = Field(description=\"List of article numbers cited from this law\", default_factory=list)\n",
    "\n",
    "class SubsectionCitations(BaseModel):\n",
    "    \"\"\"Schema for citations found in a subsection\"\"\"\n",
    "    cited_laws: List[CitedLaw] = Field(description=\"List of laws cited with their articles\", default_factory=list)\n",
    "    standalone_articles: List[str] = Field(description=\"Articles mentioned without specific law reference\", default_factory=list)\n",
    "\n",
    "class ContentCitations(BaseModel):\n",
    "    \"\"\"Schema for all citations in CONTENIDO sections\"\"\"\n",
    "    sections: dict[str, SubsectionCitations] = Field(description=\"Citations organized by section name\", default_factory=dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18db274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "def extract_citations_with_llm(text: str, section_name: str) -> SubsectionCitations:\n",
    "    \"\"\"\n",
    "    Extract legal citations from text using LLM with structured output\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "        You are a legal text analyzer. Extract all legal citations from the following text from the \"{section_name}\" section of a legal document.\n",
    "\n",
    "        Find and structure:\n",
    "        1. Laws with their specific articles (e.g., \"ley 7046\" with \"arts. 3, 14, 29\")\n",
    "        2. Articles mentioned without specific law reference (e.g., \"Art. 28\", \"del art.114\")\n",
    "\n",
    "        Text to analyze:\n",
    "        {text}\n",
    "\n",
    "        Extract ALL article and law numbers mentioned. Include ordinal numbers (1¬∫, 4¬∫) and regular numbers.\n",
    "        Be thorough and don't miss any citations, especially in sequences like \"arts. 3, 14, 29, 30, 63, 64, 71 y 94\".\n",
    "        \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.responses.parse(\n",
    "            model=DEPLOYMENT, #modify this to use responses api, as in Doc's work\n",
    "            instructions = \"You are a precise legal citation extractor. Extract all article and law numbers mentioned in legal texts. Be thorough and accurate.\",\n",
    "            input        = prompt,\n",
    "            text_format=SubsectionCitations,\n",
    "            temperature=0.1  # Low temperature for consistency\n",
    "        )\n",
    "        \n",
    "        return response.output_parsed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing section {section_name}: {e}\")\n",
    "        return SubsectionCitations()\n",
    "\n",
    "def process_json_with_llm(json_path: Path, output_path: Path):\n",
    "    \"\"\"\n",
    "    Process a single JSON file and extract citations using LLM\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)[0]  # First element of the list\n",
    "        \n",
    "        # Create output structure\n",
    "        output_structure = {\n",
    "            \"INFORMACION\": data.get(\"INFORMACION\", {}),\n",
    "            \"CONTENIDO\": {}\n",
    "        }\n",
    "        \n",
    "        # Process each subsection of CONTENIDO\n",
    "        if 'CONTENIDO' in data:\n",
    "            for section_name, paragraphs in data['CONTENIDO'].items():\n",
    "                if paragraphs:  # Only process non-empty sections\n",
    "                    # Join paragraphs into single text for analysis\n",
    "                    section_text = \"\\n\\n\".join(paragraphs) if isinstance(paragraphs, list) else str(paragraphs)\n",
    "                    \n",
    "                    # Extract citations using LLM\n",
    "                    citations = extract_citations_with_llm(section_text, section_name)\n",
    "                    \n",
    "                    # Convert to dict format for JSON serialization\n",
    "                    output_structure[\"CONTENIDO\"][section_name] = citations.model_dump()\n",
    "                    print(citations.model_dump())\n",
    "                else:\n",
    "                    # Empty section\n",
    "                    output_structure[\"CONTENIDO\"][section_name] = SubsectionCitations().model_dump()\n",
    "        \n",
    "        # Save results\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump([output_structure], f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {json_path}: {e}\")\n",
    "\n",
    "def extract_citations_with_llm_batch(json_dir: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Process all JSON files and extract citations using LLM\n",
    "    \"\"\"\n",
    "    json_root = Path(json_dir).resolve()\n",
    "    output_root = Path(output_dir).resolve()\n",
    "    output_root.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    json_files = list(json_root.rglob(\"*.json\"))\n",
    "    if not json_files:\n",
    "        print(f\"No se encontraron JSONs en {json_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ü§ñ Extrayendo citas con LLM de {len(json_files)} archivos JSON...\")\n",
    "    \n",
    "    for json_path in tqdm(json_files, desc=\"Procesando con LLM\"):\n",
    "        # Maintain folder structure\n",
    "        rel_path = json_path.relative_to(json_root)\n",
    "        output_path = output_root / rel_path\n",
    "        \n",
    "        process_json_with_llm(json_path, output_path)\n",
    "    \n",
    "    print(f\"‚úÖ Extracci√≥n con LLM completada. Archivos guardados en: {output_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d373793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Extrayendo citas con LLM de 296 archivos JSON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   0%|          | 0/296 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cited_laws': [], 'standalone_articles': ['Art. 28', 'del art. 114']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 28', 'del art. 114']}\n",
      "{'cited_laws': [{'number': 'Ley 7046', 'articles': ['arts. 112', 'arts. 113']}, {'number': 'Ley 24.522', 'articles': ['art. 267', 'art. 257']}, {'number': 'LCQ', 'articles': ['art. 267', 'art. 257']}], 'standalone_articles': ['art. 267', 'art. 257', 'art. 112', 'art. 113']}\n",
      "{'cited_laws': [], 'standalone_articles': []}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1¬∫']}\n",
      "{'cited_laws': [{'number': '8985', 'articles': []}], 'standalone_articles': ['Art. 1¬∫', 'Art. 4¬∫']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   0%|          | 1/296 [00:12<1:02:20, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cited_laws': [{'number': 'Ac. Gral. 15/18 SNE', 'articles': ['1¬∫', '4¬∫']}, {'number': 'Acuerdo Gral. 11/20', 'articles': ['23', '6', '2020']}], 'standalone_articles': []}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1¬∫', 'Art. 4¬∫', 'arts. 3', 'arts. 14', 'arts. 29', 'arts. 30', 'arts. 63', 'arts. 64', 'arts. 71', 'arts. 94']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1', 'Art. 3', 'Art. 4', 'Art. 14', 'Art. 29', 'Art. 30', 'Art. 63', 'Art. 64', 'Art. 71', 'Art. 94', 'del art. 114']}\n",
      "{'cited_laws': [{'number': 'CPCC', 'articles': ['280', '269', '281', '42']}, {'number': 'CN', 'articles': ['18']}, {'number': 'Expte.', 'articles': ['8946', '2095', '7567', '8272']}], 'standalone_articles': ['art. 280', 'art. 18', 'art. 42']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   1%|          | 2/296 [00:19<46:18,  9.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cited_laws': [{'number': 'Ac. Gral 15/18 SNE', 'articles': ['1', '4']}, {'number': 'Acuerdo Gral. 11/20', 'articles': ['23', '6', '2020']}], 'standalone_articles': ['art. 1', 'art. 4', 'Punto 4¬∞']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1', 'Art. 4', 'Art. 14', 'Art. 29', 'Art. 30', 'Art. 63', 'Art. 64', 'Art. 71', 'Art. 94', 'del art. 114']}\n",
      "{'cited_laws': [{'number': '11843', 'articles': ['1']}], 'standalone_articles': ['Art. 28', 'del art. 114']}\n",
      "{'cited_laws': [{'number': 'LOPJ', 'articles': ['61', '62', '63', '75']}, {'number': 'CPCC', 'articles': ['3', '5', '6', '38']}, {'number': 'LF nro.', 'articles': ['11843']}], 'standalone_articles': ['art. 38', 'art. 3', 'art. 75', 'art. 205 inc. 1 i)']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   1%|          | 3/296 [00:26<39:44,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cited_laws': [{'number': 'LOPJ', 'articles': ['75']}, {'number': 'Ac. Gral. 15/18 SNE', 'articles': ['1¬∫', '4¬∫']}, {'number': 'Acuerdo Gral. 11/20', 'articles': ['23', '4¬∞']}], 'standalone_articles': []}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1¬∫', 'Art. 4¬∫']}\n",
      "{'cited_laws': [{'number': 'Ley 10065', 'articles': ['arts. 1', 'arts. 2', 'arts. 3', 'arts. 4']}, {'number': 'Ley 921', 'articles': ['arts. 1', 'arts. 2']}], 'standalone_articles': ['Art. 28', 'del art. 114']}\n",
      "{'cited_laws': [{'number': 'LOPJ', 'articles': ['61', '62', '63', '75']}, {'number': 'CPP', 'articles': ['38']}, {'number': 'CPCC', 'articles': ['3', '5', '6']}, {'number': 'Constituci√≥n Provincial', 'articles': ['205']}], 'standalone_articles': ['Art. 38', 'art. 75', 'art√≠culo 61', 'art√≠culo 62', 'art√≠culo 63', 'art√≠culo 3', 'art√≠culo 5', 'art√≠culo 6', 'art√≠culo 205']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   1%|‚ñè         | 4/296 [00:33<36:40,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cited_laws': [{'number': 'LOPJ', 'articles': ['75']}, {'number': 'Ac. Gral. 15/18 SNE', 'articles': ['1¬∫', '4¬∫']}, {'number': 'Acuerdo Gral. 11/20', 'articles': ['23', '4¬∞']}], 'standalone_articles': ['art. 75', 'arts. 1¬∫', '4¬∫']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1553', 'Art. 9024']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1¬∫', 'Art. 4¬∫', 'Art. 28', 'del art. 114']}\n",
      "{'cited_laws': [{'number': 'CPP', 'articles': ['38']}, {'number': 'LOPJ', 'articles': ['61', '62', '63', '75']}, {'number': 'CPCC', 'articles': ['5', '6']}, {'number': 'Constituci√≥n Provincial', 'articles': ['205']}], 'standalone_articles': ['art. 3', 'art. 38', 'art. 75', 'art. 61', 'art. 62', 'art. 63', 'art. 5', 'art. 6', 'art. 205']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   2%|‚ñè         | 5/296 [00:39<34:10,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cited_laws': [{'number': 'LOPJ', 'articles': ['75']}, {'number': 'Ac. Gral. 15/18 SNE', 'articles': ['1¬∫', '4¬∫']}, {'number': 'Acuerdo Gral. 11/20', 'articles': ['23', '4']}], 'standalone_articles': ['art. 75', 'arts. 1¬∫', '4¬∫', 'Punto 4¬∞']}\n",
      "{'cited_laws': [{'number': '12780', 'articles': []}], 'standalone_articles': []}\n",
      "{'cited_laws': [{'number': '12780', 'articles': ['1']}], 'standalone_articles': ['Art. 1', 'art. 3', 'art. 14', 'art. 29', 'art. 30', 'art. 63', 'art. 64', 'art. 71', 'art. 94']}\n",
      "{'cited_laws': [{'number': 'LOPJ', 'articles': ['61', '62', '63', '75']}, {'number': 'CPCC', 'articles': ['3', '5', '6', '38']}, {'number': 'Constituci√≥n Provincial', 'articles': ['205']}], 'standalone_articles': ['art. 38', 'art. 3', 'art. 75']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   2%|‚ñè         | 6/296 [00:46<34:42,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cited_laws': [{'number': 'LOPJ', 'articles': ['75']}, {'number': 'Ac. Gral. 15/18 SNE', 'articles': ['1¬∫', '4¬∫']}, {'number': 'Acuerdo Gral. 11/20', 'articles': ['23', '4¬∞']}, {'number': 'L F nro. 12780', 'articles': []}], 'standalone_articles': ['art. 75', 'arts. 1¬∫', 'arts. 4¬∫', 'art. 4¬∞']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1¬∫', 'Art. 4¬∫', 'Art. 3', 'Art. 14', 'Art. 29', 'Art. 30', 'Art. 63', 'Art. 64', 'Art. 71', 'Art. 94']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 28', 'del art. 114']}\n",
      "{'cited_laws': [{'number': 'CPCC', 'articles': ['301', '248', '282', '65']}, {'number': 'ley 9776', 'articles': []}, {'number': 'CN', 'articles': ['17', '18', '19']}], 'standalone_articles': ['art. 301 inc. 3', 'art. 301 inc. d)', 'art. 248', 'art. 282']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 28', 'del art. 114']}\n",
      "{'cited_laws': [{'number': 'CIV 073468/2011/1/RH001', 'articles': []}, {'number': 'FPO 6333/2014/1/RH1', 'articles': []}], 'standalone_articles': ['Art. 1', 'Art. 2', 'Art. 3', 'Art. 4', 'Art. 28', 'del art. 114']}\n",
      "{'cited_laws': [{'number': 'ley 7046', 'articles': ['arts. 3', 'arts. 14', 'arts. 29', 'arts. 30', 'arts. 63', 'arts. 64', 'arts. 71', 'arts. 94']}], 'standalone_articles': ['Art. 28', 'del art. 114']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   2%|‚ñè         | 7/296 [00:58<41:29,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cited_laws': [{'number': 'CPCC', 'articles': ['65']}, {'number': 'Ac. Gral. 15/18 SNE', 'articles': ['1¬∫', '4¬∫']}, {'number': 'Acuerdo Gral. 11/20', 'articles': ['4¬∞']}], 'standalone_articles': ['art. 65']}\n",
      "{'cited_laws': [], 'standalone_articles': ['Art. 1¬∫', 'Art. 4¬∫']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando con LLM:   2%|‚ñè         | 7/296 [01:01<42:22,  8.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m PATH_ARTICULOS_LLM = Path(os.path.join(PATH, \u001b[33m\"\u001b[39m\u001b[33marticulos_extraidos_llm\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Execute LLM extraction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mextract_citations_with_llm_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_JSON\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH_ARTICULOS_LLM\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mextract_citations_with_llm_batch\u001b[39m\u001b[34m(json_dir, output_dir)\u001b[39m\n\u001b[32m     97\u001b[39m     rel_path = json_path.relative_to(json_root)\n\u001b[32m     98\u001b[39m     output_path = output_root / rel_path\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[43mprocess_json_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Extracci√≥n con LLM completada. Archivos guardados en: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mprocess_json_with_llm\u001b[39m\u001b[34m(json_path, output_path)\u001b[39m\n\u001b[32m     60\u001b[39m section_text = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(paragraphs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(paragraphs, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(paragraphs)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Extract citations using LLM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m citations = \u001b[43mextract_citations_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msection_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Convert to dict format for JSON serialization\u001b[39;00m\n\u001b[32m     66\u001b[39m output_structure[\u001b[33m\"\u001b[39m\u001b[33mCONTENIDO\u001b[39m\u001b[33m\"\u001b[39m][section_name] = citations.model_dump()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mextract_citations_with_llm\u001b[39m\u001b[34m(text, section_name)\u001b[39m\n\u001b[32m     12\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33m    You are a legal text analyzer. Extract all legal citations from the following text from the \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m section of a legal document.\u001b[39m\n\u001b[32m     14\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[33m    Be thorough and don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt miss any citations, especially in sequences like \u001b[39m\u001b[33m\"\u001b[39m\u001b[33marts. 3, 14, 29, 30, 63, 64, 71 y 94\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEPLOYMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#modify this to use responses api, as in Doc's work\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a precise legal citation extractor. Extract all article and law numbers mentioned in legal texts. Be thorough and accurate.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSubsectionCitations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Low temperature for consistency\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.output_parsed\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/openai/resources/responses/responses.py:936\u001b[39m, in \u001b[36mResponses.parse\u001b[39m\u001b[34m(self, input, model, text_format, tools, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, store, stream, temperature, text, tool_choice, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_response: Response) -> ParsedResponse[TextFormatT]:\n\u001b[32m    930\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parse_response(\n\u001b[32m    931\u001b[39m         input_tools=tools,\n\u001b[32m    932\u001b[39m         text_format=text_format,\n\u001b[32m    933\u001b[39m         response=raw_response,\n\u001b[32m    934\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m936\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `Response` instance into a `ParsedResponse`\u001b[39;49;00m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedResponse\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTextFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/openai/_base_client.py:969\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    967\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    975\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UDESA/NLP/TP_NLP/venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/lib/python3.12/ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.7/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Define paths\n",
    "PATH_GLOBAL = os.getcwd()\n",
    "PATH = os.path.join(PATH_GLOBAL, \"datasets\")\n",
    "PATH_JSON = Path(os.path.join(PATH, \"fallos_json\"))\n",
    "PATH_ARTICULOS_LLM = Path(os.path.join(PATH, \"articulos_extraidos_llm\"))\n",
    "\n",
    "\n",
    "# Execute LLM extraction\n",
    "extract_citations_with_llm_batch(PATH_JSON, PATH_ARTICULOS_LLM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
