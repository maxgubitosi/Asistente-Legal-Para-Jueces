{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in /Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain_community --quiet\n",
    "!pip install pypdf --quiet\n",
    "!pip install instructor --quiet\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from configs.maxi_config import API_KEY, ENDPOINT, MODEL, DEPLOYMENT\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from embeddings_wrapper import LangchainSentenceTransformer\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, ValidationError, Field\n",
    "from openai import AsyncAzureOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cargando y dividiendo el PDF...\n",
      "[INFO] Total de fragmentos generados: 4\n",
      "[INFO] Generando embeddings...\n",
      "[INFO] Filtering 4 chunks...\n",
      "[INFO] Embedding 4 clean chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# Lee un solo PDF\n",
    "pdf_path = \"datasets/2024/02/8142.pdf\"\n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    raise FileNotFoundError(f\"No se encontró el archivo: {pdf_path}\")\n",
    "\n",
    "# --- Cargar y dividir el PDF ---\n",
    "print(\"[INFO] Cargando y dividiendo el PDF...\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=128)\n",
    "\n",
    "try:\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    chunks = splitter.split_documents(documents)\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] No se pudo procesar el PDF: {e}\")\n",
    "    chunks = []\n",
    "\n",
    "print(f\"[INFO] Total de fragmentos generados: {len(chunks)}\")\n",
    "\n",
    "# --- Embeddings y FAISS ---\n",
    "print(\"[INFO] Generando embeddings...\")\n",
    "embedding_model = LangchainSentenceTransformer()\n",
    "texts, embeddings = embedding_model.embed_documents(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "text_embedding_pairs = list(zip(texts, embeddings))\n",
    "vectorstore = FAISS.from_embeddings(text_embedding_pairs, embedding_model)\n",
    "vectorstore.save_local(\"datasets/fallo_8142_vectorstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear archivo con data de api, y dejarlo afuera del repo, que aca se llame a eso!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(query):\n",
    "    results = vectorstore.similarity_search(query, k=5)\n",
    "    # for i, doc in enumerate(results, 1):\n",
    "    #     print(f\"{i}. {doc.page_content.strip()}\\n\")\n",
    "    return results\n",
    "\n",
    "azure_client = AsyncAzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "async def get_response(query):\n",
    "    res = await azure_client.chat.completions.create(\n",
    "        model=DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. Tu tarea es analizar el contexto y responder de manera precisa y concisa.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"El contexto es: {create_context(query)}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await get_response(\"Que dice el fallo dado?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El fallo se refiere a la regulación de honorarios profesionales por los recursos de inaplicabilidad de ley resueltos en dos fechas: 25 de junio de 2020 y 10 de abril de 2023. Se establecen las siguientes sumas a pagar a cada abogado: \\n\\n1. Para el recurso de 25/6/2020:\\n   - Dr. Ricardo Abraham Salvador: $63.900\\n   - Dr. Julio Eduardo Amaduzzi: $22.365\\n   - Dr. Nicolás Eduardo Bruno: $22.365\\n\\n2. Para el recurso de 10/4/2023:\\n   - Dr. Ricardo Abraham Salvador: $213.000\\n   - Dra. María Antonella Arlettaz: $74.550\\n   - Dr. Diego G. Spinelli: $74.550\\n\\nAsimismo, el fallo ha seguido disposiciones legales sobre la notificación y el pago de honorarios, incluyendo detalles sobre aplicación de intereses en caso de mora. Se indica que se notifique conforme a los procedimientos establecidos y se registre adecuadamente.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta = response.choices[0].message.content\n",
    "respuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El fallo se refiere a la regulación de honorarios profesionales por los recursos de inaplicabilidad de ley resueltos en dos fechas: 25 de junio de 2020 y 10 de abril de 2023. Se establecen las siguientes sumas a pagar a cada abogado: \n",
       "\n",
       "1. Para el recurso de 25/6/2020:\n",
       "   - Dr. Ricardo Abraham Salvador: $63.900\n",
       "   - Dr. Julio Eduardo Amaduzzi: $22.365\n",
       "   - Dr. Nicolás Eduardo Bruno: $22.365\n",
       "\n",
       "2. Para el recurso de 10/4/2023:\n",
       "   - Dr. Ricardo Abraham Salvador: $213.000\n",
       "   - Dra. María Antonella Arlettaz: $74.550\n",
       "   - Dr. Diego G. Spinelli: $74.550\n",
       "\n",
       "Asimismo, el fallo ha seguido disposiciones legales sobre la notificación y el pago de honorarios, incluyendo detalles sobre aplicación de intereses en caso de mora. Se indica que se notifique conforme a los procedimientos establecidos y se registre adecuadamente."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "display(Markdown(respuesta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptar esto para que tome los jsons creados por Toni!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
