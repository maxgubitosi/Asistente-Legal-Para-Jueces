{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "780d0545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'main_source_cited_articles_stats.json' generado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Ruta base donde buscar los archivos .json\n",
    "base_dir = \"../datasets/fallos_json\"\n",
    "\n",
    "# Diccionario para almacenar la informaciÃ³n\n",
    "result = {}\n",
    "\n",
    "# Recorrer todas las carpetas y archivos .json\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "                    citations = (\n",
    "                        data.get(\"METADATOS\", {})\n",
    "                        .get(\"ARTICULOS_CITADOS\", {})\n",
    "                        .get(\"citations\", [])\n",
    "                    )\n",
    "                    for citation in citations:\n",
    "                        main_source = citation.get(\"main_source\")\n",
    "                        cited_articles = citation.get(\"cited_articles\", [])\n",
    "                        if main_source is not None and cited_articles is not None:\n",
    "                            if main_source not in result:\n",
    "                                result[main_source] = []\n",
    "                            result[main_source].extend(cited_articles)\n",
    "            except Exception as e:\n",
    "                print(f\"Error en {file_path}: {e}\")\n",
    "\n",
    "# Construir el JSON de salida\n",
    "output = {}\n",
    "for source, articles in result.items():\n",
    "    freq = Counter(articles)\n",
    "    output[source] = {\n",
    "        \"cited_articles_frequency\": dict(freq),\n",
    "        \"total_cited_articles\": sum(freq.values())\n",
    "    }\n",
    "\n",
    "# Guardar el resultado en un archivo\n",
    "with open(\"main_source_cited_articles_stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Archivo 'main_source_cited_articles_stats.json' generado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51915c3e",
   "metadata": {},
   "source": [
    "# Prueba del procesador enriquecido de fallos legales\n",
    "\n",
    "Vamos a procesar los archivos JSON usando el nuevo procesador y mostrar algunos fragmentos enriquecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0035b40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de fragmentos extraÃ­dos: 578\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "from typing import Iterator, Set, Dict, Any\n",
    "from pydantic import ValidationError\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LegalParagraphEnriched(BaseModel):\n",
    "    \"\"\"Modelo enriquecido para pÃ¡rrafos legales con contexto adicional\"\"\"\n",
    "    expediente: str = Field(..., description=\"NÃºmero de expediente\")\n",
    "    section: str = Field(..., description=\"SecciÃ³n del documento\")\n",
    "    paragraph_id: int = Field(..., ge=0, description=\"ID del pÃ¡rrafo dentro de la secciÃ³n\")\n",
    "    text: str = Field(..., min_length=1, description=\"Contenido del pÃ¡rrafo\")\n",
    "    path: str = Field(..., description=\"Ruta relativa del archivo fuente\")\n",
    "    idea_central: Optional[str] = Field(None, description=\"Idea central del fallo\")\n",
    "    articulos_citados: Optional[List[Dict[str, Any]]] = Field(None, description=\"ArtÃ­culos citados en el fallo\")\n",
    "    materia_preliminar: Optional[str] = Field(None, description=\"Materia preliminar del fallo\")\n",
    "    metadatos: Optional[Dict[str, Any]] = Field(None, description=\"Metadatos adicionales del fallo\")\n",
    "\n",
    "    def to_search_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convierte a formato para bÃºsqueda\"\"\"\n",
    "        return {\n",
    "            \"expte\": self.expediente,\n",
    "            \"section\": self.section,\n",
    "            \"paragraph\": self.text,\n",
    "            \"path\": self.path,\n",
    "            \"paragraph_id\": self.paragraph_id,\n",
    "            \"idea_central\": self.idea_central,\n",
    "            \"articulos_citados\": self.articulos_citados,\n",
    "            \"materia_preliminar\": self.materia_preliminar,\n",
    "            \"metadatos\": self.metadatos\n",
    "        }\n",
    "\n",
    "\n",
    "class EnrichedProcessor:\n",
    "    \"\"\"Procesador que extrae fragmentos enriquecidos de los fallos JSON\"\"\"\n",
    "    def __init__(self):\n",
    "        self.stats = {\n",
    "            \"files_processed\": 0,\n",
    "            \"paragraphs_extracted\": 0,\n",
    "            \"expedientes_found\": set(),\n",
    "            \"errors\": []\n",
    "        }\n",
    "\n",
    "    def process_directory(self, json_dir: Path) -> Iterator[LegalParagraphEnriched]:\n",
    "        \"\"\"Procesa todos los archivos JSON en el directorio y subdirectorios\"\"\"\n",
    "        json_files = list(json_dir.rglob(\"*.json\"))\n",
    "        logger.info(f\"ðŸ“„ Encontrados {len(json_files)} archivos\")\n",
    "        for file_path in json_files:\n",
    "            try:\n",
    "                yield from self._process_file(file_path, json_dir)\n",
    "                self.stats[\"files_processed\"] += 1\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error en {file_path.name}: {str(e)}\"\n",
    "                logger.error(error_msg)\n",
    "                self.stats[\"errors\"].append(error_msg)\n",
    "                continue\n",
    "        logger.info(f\"âœ… Procesamiento completado: {self.stats}\")\n",
    "\n",
    "    def _process_file(self, file_path: Path, base_dir: Path) -> Iterator[LegalParagraphEnriched]:\n",
    "        content = file_path.read_text(encoding=\"utf-8\")\n",
    "        docs = json.loads(content)\n",
    "        if not isinstance(docs, list):\n",
    "            docs = [docs]\n",
    "        for doc in docs:\n",
    "            yield from self._process_document(doc, file_path, base_dir)\n",
    "\n",
    "    def _process_document(self, doc: Dict[str, Any], file_path: Path, base_dir: Path) -> Iterator[LegalParagraphEnriched]:\n",
    "        contenido = doc[\"CONTENIDO\"]\n",
    "        expte = self._extract_expediente(contenido[\"INICIO\"][0])\n",
    "        idea_central = doc.get(\"IDEA_CENTRAL\")\n",
    "        articulos_citados = doc.get(\"METADATOS\", {}).get(\"ARTICULOS_CITADOS\", {}).get(\"citations\", [])\n",
    "        materia_preliminar = doc.get(\"MATERIA_PRELIMINAR\")\n",
    "        metadatos = doc.get(\"METADATOS\", {})\n",
    "        self.stats[\"expedientes_found\"].add(expte)\n",
    "        for section, paragraphs in contenido.items():\n",
    "            if not isinstance(paragraphs, list):\n",
    "                continue\n",
    "            for idx, text in enumerate(paragraphs):\n",
    "                if not text or not isinstance(text, str) or len(text.strip()) < 10:\n",
    "                    continue\n",
    "                try:\n",
    "                    paragraph = LegalParagraphEnriched(\n",
    "                        expediente=expte,\n",
    "                        section=section,\n",
    "                        paragraph_id=idx,\n",
    "                        text=text,\n",
    "                        path=file_path.relative_to(base_dir).as_posix(),\n",
    "                        idea_central=idea_central,\n",
    "                        articulos_citados=articulos_citados,\n",
    "                        materia_preliminar=materia_preliminar,\n",
    "                        metadatos=metadatos\n",
    "                    )\n",
    "                    self.stats[\"paragraphs_extracted\"] += 1\n",
    "                    yield paragraph\n",
    "                except ValidationError:\n",
    "                    continue\n",
    "\n",
    "    def _extract_expediente(self, header: str) -> str:\n",
    "        for pattern in [\"Expte. NÂº\", \"Expediente\", \"Exp.\"]:\n",
    "            if pattern in header:\n",
    "                return header.split(pattern)[-1].strip().split()[0]\n",
    "        import hashlib\n",
    "        return hashlib.md5(header.encode()).hexdigest()[:8].upper()\n",
    "\n",
    "    def get_stats(self) -> dict:\n",
    "        return {\n",
    "            \"processor_type\": \"enriched\",\n",
    "            \"files_processed\": self.stats[\"files_processed\"],\n",
    "            \"paragraphs_extracted\": self.stats[\"paragraphs_extracted\"],\n",
    "            \"expedientes_found\": len(self.stats[\"expedientes_found\"]),\n",
    "            \"errors\": len(self.stats[\"errors\"]),\n",
    "            \"error_rate\": len(self.stats[\"errors\"]) / max(1, self.stats[\"files_processed\"])\n",
    "        }\n",
    "\n",
    "\n",
    "# Ruta al directorio de fallos JSON\n",
    "json_dir = Path(\"datasets/fallos_json/2024/07\")\n",
    "\n",
    "# Instanciar el procesador enriquecido\n",
    "processor = EnrichedProcessor()\n",
    "\n",
    "# Procesar el directorio y obtener los fragmentos enriquecidos\n",
    "fragmentos = list(processor.process_directory(json_dir))\n",
    "\n",
    "print(f\"Total de fragmentos extraÃ­dos: {len(fragmentos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba46fb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expte: 8554\n",
      "SecciÃ³n: INICIO\n",
      "Texto: \"FIGUEROA MERCEDES NOEMI POR SI Y EN NOMBRE Y REPRESENTACIÃ“N DE SUS HIJOS MENORES DE EDAD C/ FONTANINI CRISTIAN MATIAS Y OTROS S/ ORDINARIO ACCIDENTES DE TRANSITO\" - Expte. NÂº 8554\n",
      "Idea central: **IDEA CENTRAL DEL FALLO:**\n",
      "\n",
      "El Tribunal declarÃ³ inadmisible el recurso de inaplicabilidad de ley in\n",
      "ArtÃ­culos citados: [{'main_source': 'Ley 24.449', 'cited_articles': [68], 'extra': None}, {'main_source': 'Ley 7046', 'cited_articles': [64, 3, 30, 63, 94], 'extra': 'modif. por ley 11.141'}, {'main_source': 'CÃ³digo Procesal Civil y Comercial (CPCC)', 'cited_articles': [65, 277, 280], 'extra': None}, {'main_source': 'Acuerdo General 15/18 SNE', 'cited_articles': [1, 4], 'extra': None}, {'main_source': 'Acuerdo General 11/20', 'cited_articles': [0], 'extra': 'del 23-6-2020'}, {'main_source': 'Otro', 'cited_articles': [56, 118, 29, 28, 114], 'extra': 'pÃ¡rr. 3, de la Ley 17.148'}]\n",
      "Materia: ORDINARIO ACCIDENTES DE TRANSITO\n",
      "------------------------------------------------------------\n",
      "Expte: 8554\n",
      "SecciÃ³n: ACUERDO\n",
      "Texto: En la ciudad de ParanÃ¡, capital de la provincia de Entre RÃ­os, a los veintidÃ³s dÃ­as del mes de julio del aÃ±o dos mil veinticuatro reunidos los integrantes de este Tribunal asistidos por el Secretario autorizante, para conocer el recurso de inaplicabilidad de ley deducido en fecha 7/7/2023 en las actuaciones: \"FIGUEROA MERCEDES NOEMI POR SI Y EN NOMBRE Y REPRESENTACIÃ“N DE SUS HIJOS MENORES DE EDAD C/ FONTANINI CRISTIAN MATIAS Y OTROS S/ ORDINARIO ACCIDENTES DE TRANSITO\" - Expte. NÂº 8554, respecto de la resoluciÃ³n de la Sala Tercera de la CÃ¡mara Segunda de Apelaciones de ParanÃ¡ dictada en fecha 22/6/2023. Que la votaciÃ³n debe tener lugar en el siguiente orden: Sr.\n",
      "Idea central: **IDEA CENTRAL DEL FALLO:**\n",
      "\n",
      "El Tribunal declarÃ³ inadmisible el recurso de inaplicabilidad de ley in\n",
      "ArtÃ­culos citados: [{'main_source': 'Ley 24.449', 'cited_articles': [68], 'extra': None}, {'main_source': 'Ley 7046', 'cited_articles': [64, 3, 30, 63, 94], 'extra': 'modif. por ley 11.141'}, {'main_source': 'CÃ³digo Procesal Civil y Comercial (CPCC)', 'cited_articles': [65, 277, 280], 'extra': None}, {'main_source': 'Acuerdo General 15/18 SNE', 'cited_articles': [1, 4], 'extra': None}, {'main_source': 'Acuerdo General 11/20', 'cited_articles': [0], 'extra': 'del 23-6-2020'}, {'main_source': 'Otro', 'cited_articles': [56, 118, 29, 28, 114], 'extra': 'pÃ¡rr. 3, de la Ley 17.148'}]\n",
      "Materia: ORDINARIO ACCIDENTES DE TRANSITO\n",
      "------------------------------------------------------------\n",
      "Expte: 8554\n",
      "SecciÃ³n: ACUERDO\n",
      "Texto: Vocal Carlos Federico Tepsich; Sra. Vocal Gisela N. Schumacher y Sr. Vocal Leonardo Portela.\n",
      "Idea central: **IDEA CENTRAL DEL FALLO:**\n",
      "\n",
      "El Tribunal declarÃ³ inadmisible el recurso de inaplicabilidad de ley in\n",
      "ArtÃ­culos citados: [{'main_source': 'Ley 24.449', 'cited_articles': [68], 'extra': None}, {'main_source': 'Ley 7046', 'cited_articles': [64, 3, 30, 63, 94], 'extra': 'modif. por ley 11.141'}, {'main_source': 'CÃ³digo Procesal Civil y Comercial (CPCC)', 'cited_articles': [65, 277, 280], 'extra': None}, {'main_source': 'Acuerdo General 15/18 SNE', 'cited_articles': [1, 4], 'extra': None}, {'main_source': 'Acuerdo General 11/20', 'cited_articles': [0], 'extra': 'del 23-6-2020'}, {'main_source': 'Otro', 'cited_articles': [56, 118, 29, 28, 114], 'extra': 'pÃ¡rr. 3, de la Ley 17.148'}]\n",
      "Materia: ORDINARIO ACCIDENTES DE TRANSITO\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los primeros 3 fragmentos enriquecidos\n",
    "for frag in fragmentos[:3]:\n",
    "    print(f\"Expte: {frag.expediente}\")\n",
    "    print(f\"SecciÃ³n: {frag.section}\")\n",
    "    print(f\"Texto: {frag.text}\")\n",
    "    print(f\"Idea central: {frag.idea_central[:100] if frag.idea_central else None}\")\n",
    "    print(f\"ArtÃ­culos citados: {frag.articulos_citados}\")\n",
    "    print(f\"Materia: {frag.materia_preliminar}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d275b",
   "metadata": {},
   "source": [
    "Si ves los campos extra correctamente poblados, Â¡el procesador estÃ¡ funcionando bien!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
