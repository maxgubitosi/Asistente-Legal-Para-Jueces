{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29cf294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, glob\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from IPython.display import display, Markdown\n",
    "import asyncio\n",
    "from openai import AsyncAzureOpenAI\n",
    "from configs.credentials_config import API_KEY, ENDPOINT, MODEL, DEPLOYMENT, EMBEDDINGS_API_KEY, EMBEDDINGS_ENDPOINT, EMBEDDINGS_VERSION, EMBEDDINGS_DEPLOYMENT # Crear archivo credentials_config.py con las credenciales de Azure OpenAI siguiendo el template\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from embeddings_wrapper import LangchainSentenceTransformer, AzureOpenAIEmbedder\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, ValidationError, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15491519",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORSTORE_PATH = \"datasets/fallos_vectorstore_ada-002\"\n",
    "EMBEDDINGS_OPTION = \"azure_openai\" # \"langchain\" or \"azure_openai\"\n",
    "EMBEDDINGS_MODEL = \"mixedbread-ai/mxbai-embed-large-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba5e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de vectores en FAISS index: 4918\n",
      "Total de Document en docstore: 4918\n",
      "\n",
      "--- Primeros 5 Documentos ---\n",
      "ID: 6c42f9cd-a447-40c4-b3c8-cc7b383a4a69\n",
      "Texto (fragmento): '\"URBANOTEC S.A. S/ QUIEBRA\" - Expte. Nº 8985'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 3d97289c-d85d-4a48-9c57-e9340a4457a5\n",
      "Texto (fragmento): 'En la ciudad de Paraná, capital de la provincia de Entre Ríos, a los veinticinco días del mes de mar'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 0dc1a4e6-b40c-4b06-b020-1380f459886d\n",
      "Texto (fragmento): '1.- La sentencia de Camara que viene recurrida La sentencia de la Cámara de Apelaciones Sala Primera'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: ea826322-316b-4b29-a862-28370371fe45\n",
      "Texto (fragmento): 'En consecuencia redujo los honorarios de los letrados Angelini y Bargas a la suma de pesos quiniento'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 853f57c5-2dfb-4d1e-9ea2-bd847ffd569f\n",
      "Texto (fragmento): 'Para así decidir la Cámara, luego de establecer los agravios de los recurrentes, sostuvo que la cues'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "\n",
      "=== Estadísticas generales ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total fallos únicos</th>\n",
       "      <th>Total chunks</th>\n",
       "      <th>Secciones únicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total fallos únicos  Total chunks  Secciones únicas\n",
       "0                    0          4918                 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chunks por fuente (fallo) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuente</th>\n",
       "      <th>n_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fuente, n_chunks]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chunks por sección ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seccion</th>\n",
       "      <th>n_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seccion, n_chunks]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IDEA DE COMO CARGAR VECTORSTORE: MODIFICAR EL ORIGINAL PARA QUE TENGA METADATOS PARA:\n",
    "# * fuente: nombre del fallo (ej. \"8104\")\n",
    "# * seccion: sección del fallo (ej. \"Antecedentes\", \"Fundamentos de Derecho\", etc.)\n",
    "\n",
    "# 1. Cargar el índice FAISS desde el disco\n",
    "db = FAISS.load_local(\n",
    "    VECTORSTORE_PATH,\n",
    "    embeddings=None,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 2. Cantidad total de vectores (# chunks) \n",
    "print(\"Total de vectores en FAISS index:\", db.index.ntotal)\n",
    "\n",
    "# 3. Revisar cuántos Document guarda el docstore\n",
    "docs_dict = db.docstore._dict\n",
    "print(\"Total de Document en docstore:\", len(docs_dict))\n",
    "\n",
    "# 4. Inspeccionar los primeros 5 Document para ver texto y metadata\n",
    "print(\"\\n--- Primeros 5 Documentos ---\")\n",
    "for i, (doc_id, doc) in enumerate(docs_dict.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(\"Texto (fragmento):\", repr(doc.page_content[:100]) + \"…\")\n",
    "    print(\"Metadatos:\", doc.metadata)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# 5. Convertir metadata a DataFrame para análisis completo\n",
    "records = []\n",
    "for doc in docs_dict.values():\n",
    "    # Si metadata estuviera vacío, aparecerán valores por defecto\n",
    "    records.append({\n",
    "        \"fuente\":  doc.metadata.get(\"fuente\", None),\n",
    "        \"seccion\": doc.metadata.get(\"seccion\", None),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 5.a. Número de fallos distintos y chunks\n",
    "print(\"\\n=== Estadísticas generales ===\")\n",
    "summary = pd.DataFrame({\n",
    "    \"Total fallos únicos\":  [df[\"fuente\"].nunique(dropna=True)],\n",
    "    \"Total chunks\":         [len(df)],\n",
    "    \"Secciones únicas\":     [df[\"seccion\"].nunique(dropna=True)],\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "# 5.b. Chunks por 'fuente'\n",
    "chunks_per_fallo = (\n",
    "    df.groupby(\"fuente\")\n",
    "      .size()\n",
    "      .reset_index(name=\"n_chunks\")\n",
    "      .sort_values(\"n_chunks\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== Chunks por fuente (fallo) ===\")\n",
    "display(chunks_per_fallo)\n",
    "\n",
    "# 5.c. Chunks por 'seccion'\n",
    "chunks_per_seccion = (\n",
    "    df.groupby(\"seccion\")\n",
    "      .size()\n",
    "      .reset_index(name=\"n_chunks\")\n",
    "      .sort_values(\"n_chunks\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== Chunks por sección ===\")\n",
    "display(chunks_per_seccion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "if EMBEDDINGS_OPTION == \"langchain\":\n",
    "    embedding_model = LangchainSentenceTransformer(model_name = EMBEDDINGS_MODEL)\n",
    "    \n",
    "elif EMBEDDINGS_OPTION == \"azure_openai\":\n",
    "    embedding_model = AzureOpenAIEmbedder(\n",
    "        deployment_name = EMBEDDINGS_DEPLOYMENT,\n",
    "        endpoint        = EMBEDDINGS_ENDPOINT,\n",
    "        api_key         = EMBEDDINGS_API_KEY,\n",
    "        api_version     = EMBEDDINGS_VERSION,\n",
    "    )\n",
    "\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"datasets/fallos_vectorstore_ada-002\", \n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "\n",
    "def create_context(query):\n",
    "    results = vectorstore.similarity_search(query, k=5)\n",
    "    # for i, doc in enumerate(results, 1):\n",
    "    #     print(f\"{i}. {doc.page_content.strip()}\\n\")\n",
    "    return results\n",
    "\n",
    "azure_client = AsyncAzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "async def get_response(query):\n",
    "    res = await azure_client.chat.completions.create(\n",
    "        model=DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. Tu tarea es analizar el contexto y responder de manera precisa y concisa.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"El contexto es: {create_context(query)}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fb59da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await get_response(\"Explicame el fallo que dice: TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS -  Expte. Nº 8142\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78f3381d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El fallo correspondiente al expediente \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\" se refiere a un proceso judicial en el cual Alcides Vicente Terenzano demanda a Marta Olga Landivar y a otro demandado por un cobro de pesos. \n",
       "\n",
       "El tribunal considera la solicitud de regulación de honorarios presentada el 7 de diciembre de 2023, relacionada con la actuación profesional en recursos de inaplicabilidad de ley que fueron resueltos en fechas anteriores (25 de junio de 2020 y 10 de abril de 2023). Para este proceso, se toma en cuenta la normativa arancelaria aplicable, citando varios artículos de la ley 7046 que regulan tales situaciones.\n",
       "\n",
       "En resumen, el fallo se centra en la regulación de honorarios por el trabajo realizado en los mencionados recursos, ajustándose a la legislación pertinente y la liquidación económica aprobada previamente."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "respuesta = response.choices[0].message.content\n",
    "display(Markdown(respuesta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c33d674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Consulta: TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\n",
      "================================================================================\n",
      "\n",
      "📊 Top 5 documentos más similares:\n",
      "\n",
      "🏆 Resultado #1 - Score: 0.1322\n",
      "📁 Fuente: N/A\n",
      "📋 Sección: N/A\n",
      "📄 Contenido: \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\"- Expte. Nº 8142.\n",
      "PARANÁ, 5 de febrero de 2024....\n",
      "--------------------------------------------------------------------------------\n",
      "🏆 Resultado #2 - Score: 0.2176\n",
      "📁 Fuente: N/A\n",
      "📋 Sección: N/A\n",
      "📄 Contenido: Que los autos \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\" - Expte. Nº 8142, vienen a consideración de este Tribunal en virtud de la solicitud de regulación de honorarios de fecha 7/12/2023, por la actuación profesional en los recursos de inaplicabilidad de...\n",
      "--------------------------------------------------------------------------------\n",
      "🏆 Resultado #3 - Score: 0.2483\n",
      "📁 Fuente: N/A\n",
      "📋 Sección: N/A\n",
      "📄 Contenido: \"PÉREZ, Eusebio Antonio C/ ZAMPEDRI, Adrián Edgardo S/ ORDINARIO ACCION REIVINDICATORIA\"- Expte. Nº 9111\"...\n",
      "--------------------------------------------------------------------------------\n",
      "🏆 Resultado #4 - Score: 0.2490\n",
      "📁 Fuente: N/A\n",
      "📋 Sección: N/A\n",
      "📄 Contenido: \"GIOVANARDI DE GRAZIANO, MARTA GRACIELA C/ WARNER, VANINA Y OTRO ORDINARIO- S/ EJECUCION DE SENTENCIA (Promovida parcialmente contra Alcides Marcelo LÓPEZ - Expte. Nº 10120)\" - Expte. Nº 8543.\n",
      "PARANÁ, 21 de octubre de 2024....\n",
      "--------------------------------------------------------------------------------\n",
      "🏆 Resultado #5 - Score: 0.2570\n",
      "📁 Fuente: N/A\n",
      "📋 Sección: N/A\n",
      "📄 Contenido: \"CORBETTO RODOLFO LUIS C VERCESI CARLOS UBALDO S ORDINARIO ACCION REIVINDICATORIA S/ QUEJA (INTERPUESTA POR LA DRA MARIA AMELIA ANGEROSA DE CESPEDES)\" - Expte.\n",
      "N° 9158 PARANA, 7 de noviembre de 2024....\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyze_similarity_results(query, k=5):\n",
    "    \"\"\"\n",
    "    Analiza y muestra los resultados de similitud para una consulta\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Consulta: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Obtener resultados con scores de similitud\n",
    "    if hasattr(vectorstore, 'similarity_search_with_score'):\n",
    "        results_with_scores = vectorstore.similarity_search_with_score(query, k=k)\n",
    "        \n",
    "        print(f\"\\n📊 Top {k} documentos más similares:\\n\")\n",
    "        \n",
    "        for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "            print(f\"🏆 Resultado #{i} - Score: {score:.4f}\")\n",
    "            print(f\"📁 Fuente: {doc.metadata.get('fuente', 'N/A')}\")\n",
    "            print(f\"📋 Sección: {doc.metadata.get('seccion', 'N/A')}\")\n",
    "            print(f\"📄 Contenido: {doc.page_content[:300]}...\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        return results_with_scores\n",
    "    else:\n",
    "        # Fallback si no tiene similarity_search_with_score\n",
    "        results = vectorstore.similarity_search(query, k=k)\n",
    "        \n",
    "        print(f\"\\n📊 Top {k} documentos más similares:\\n\")\n",
    "        \n",
    "        for i, doc in enumerate(results, 1):\n",
    "            print(f\"🏆 Resultado #{i}\")\n",
    "            print(f\"📁 Fuente: {doc.metadata.get('fuente', 'N/A')}\")\n",
    "            print(f\"📋 Sección: {doc.metadata.get('seccion', 'N/A')}\")\n",
    "            print(f\"📄 Contenido: {doc.page_content[:300]}...\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        return results\n",
    "\n",
    "# Ejemplo de uso\n",
    "query_test = \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\"\n",
    "similarity_results = analyze_similarity_results(query_test, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e66033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_with_metadata(query, k=5):\n",
    "    \"\"\"\n",
    "    Crea contexto incluyendo metadatos para mejor trazabilidad\n",
    "    \"\"\"\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    \n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        fuente = doc.metadata.get('fuente', 'N/A')\n",
    "        seccion = doc.metadata.get('seccion', 'N/A')\n",
    "        \n",
    "        context_part = f\"\"\"\n",
    "Documento {i}:\n",
    "Fuente: {fuente}\n",
    "Sección: {seccion}\n",
    "Contenido: {doc.page_content.strip()}\n",
    "\"\"\"\n",
    "        context_parts.append(context_part)\n",
    "    \n",
    "    return \"\\n\".join(context_parts), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1262bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para evaluación ELO\n",
    "class RAGEvaluator:\n",
    "    def __init__(self, vectorstore, azure_client, deployment):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.azure_client = azure_client\n",
    "        self.deployment = deployment\n",
    "        \n",
    "    async def get_rag_response(self, query, k=5, system_prompt=None):\n",
    "        \"\"\"\n",
    "        Obtiene respuesta RAG con contexto recuperado\n",
    "        \"\"\"\n",
    "        context, retrieved_docs = create_context_with_metadata(query, k=k)\n",
    "        \n",
    "        if system_prompt is None:\n",
    "            system_prompt = \"\"\"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. \n",
    "            Tu tarea es analizar el contexto proporcionado y responder de manera precisa y concisa, citando las fuentes cuando sea relevante.\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"system\", \"content\": f\"Contexto de documentos relevantes:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        \n",
    "        response = await self.azure_client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=messages,\n",
    "            temperature=0.1  # Baja temperatura para consistencia\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'response': response.choices[0].message.content,\n",
    "            'retrieved_docs': retrieved_docs,\n",
    "            'context': context\n",
    "        }\n",
    "    \n",
    "    async def evaluate_response_quality(self, query, response_a, response_b):\n",
    "        \"\"\"\n",
    "        Evalúa qué respuesta es mejor usando el modelo como juez\n",
    "        \"\"\"\n",
    "        evaluation_prompt = f\"\"\"\n",
    "Eres un juez experto evaluando respuestas de un sistema de preguntas y respuestas sobre fallos judiciales.\n",
    "\n",
    "Pregunta: {query}\n",
    "\n",
    "Respuesta A: {response_a}\n",
    "\n",
    "Respuesta B: {response_b}\n",
    "\n",
    "Evalúa qué respuesta es mejor considerando:\n",
    "1. Precisión factual\n",
    "2. Relevancia al caso específico\n",
    "3. Claridad y estructura\n",
    "4. Uso apropiado del contexto legal\n",
    "\n",
    "Responde únicamente con: \"A\", \"B\", o \"EMPATE\"\n",
    "\"\"\"\n",
    "        \n",
    "        response = await self.azure_client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=[{\"role\": \"user\", \"content\": evaluation_prompt}],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content.strip().upper()\n",
    "        return result if result in [\"A\", \"B\", \"EMPATE\"] else \"EMPATE\"\n",
    "\n",
    "# Crear evaluador\n",
    "evaluator = RAGEvaluator(vectorstore, azure_client, DEPLOYMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6e6fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class ELOSystem:\n",
    "    def __init__(self, k_factor=32, initial_rating=1500):\n",
    "        self.k_factor = k_factor\n",
    "        self.initial_rating = initial_rating\n",
    "        self.ratings = defaultdict(lambda: initial_rating)\n",
    "        self.match_history = []\n",
    "    \n",
    "    def expected_score(self, rating_a, rating_b):\n",
    "        \"\"\"Calcula la probabilidad esperada de que A gane contra B\"\"\"\n",
    "        return 1 / (1 + 10**((rating_b - rating_a) / 400))\n",
    "    \n",
    "    def update_ratings(self, player_a, player_b, result):\n",
    "        \"\"\"\n",
    "        Actualiza ratings basado en el resultado\n",
    "        result: 1 si A gana, 0 si B gana, 0.5 si empate\n",
    "        \"\"\"\n",
    "        rating_a = self.ratings[player_a]\n",
    "        rating_b = self.ratings[player_b]\n",
    "        \n",
    "        expected_a = self.expected_score(rating_a, rating_b)\n",
    "        expected_b = self.expected_score(rating_b, rating_a)\n",
    "        \n",
    "        new_rating_a = rating_a + self.k_factor * (result - expected_a)\n",
    "        new_rating_b = rating_b + self.k_factor * ((1 - result) - expected_b)\n",
    "        \n",
    "        self.ratings[player_a] = new_rating_a\n",
    "        self.ratings[player_b] = new_rating_b\n",
    "        \n",
    "        # Guardar historial\n",
    "        self.match_history.append({\n",
    "            'player_a': player_a,\n",
    "            'player_b': player_b,\n",
    "            'result': result,\n",
    "            'rating_a_before': rating_a,\n",
    "            'rating_b_before': rating_b,\n",
    "            'rating_a_after': new_rating_a,\n",
    "            'rating_b_after': new_rating_b\n",
    "        })\n",
    "        \n",
    "        return new_rating_a, new_rating_b\n",
    "    \n",
    "    def get_leaderboard(self):\n",
    "        \"\"\"Retorna leaderboard ordenado por rating\"\"\"\n",
    "        return sorted(self.ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Inicializar sistema ELO\n",
    "elo_system = ELOSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a475d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_elo_evaluation(queries, configurations):\n",
    "    \"\"\"\n",
    "    Ejecuta evaluación ELO entre diferentes configuraciones de RAG\n",
    "    \n",
    "    queries: Lista de preguntas de prueba\n",
    "    configurations: Dict con diferentes configuraciones {name: config_dict}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🎯 Iniciando evaluación ELO...\")\n",
    "    \n",
    "    # Generar todas las respuestas\n",
    "    all_responses = {}\n",
    "    \n",
    "    for config_name, config in configurations.items():\n",
    "        print(f\"📝 Generando respuestas para configuración: {config_name}\")\n",
    "        all_responses[config_name] = {}\n",
    "        \n",
    "        for query in tqdm(queries, desc=f\"Procesando {config_name}\"):\n",
    "            try:\n",
    "                result = await evaluator.get_rag_response(\n",
    "                    query, \n",
    "                    k=config.get('k', 5),\n",
    "                    system_prompt=config.get('system_prompt', None)\n",
    "                )\n",
    "                all_responses[config_name][query] = result['response']\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error en {config_name} para query '{query[:50]}...': {e}\")\n",
    "                all_responses[config_name][query] = \"Error en generación\"\n",
    "    \n",
    "    # Realizar comparaciones ELO\n",
    "    print(\"\\n⚔️ Realizando comparaciones ELO...\")\n",
    "    \n",
    "    config_names = list(configurations.keys())\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    for i, config_a in enumerate(config_names):\n",
    "        for j, config_b in enumerate(config_names[i+1:], i+1):\n",
    "            print(f\"\\n🥊 {config_a} vs {config_b}\")\n",
    "            \n",
    "            for query in tqdm(queries, desc=\"Comparando\"):\n",
    "                response_a = all_responses[config_a][query]\n",
    "                response_b = all_responses[config_b][query]\n",
    "                \n",
    "                if \"Error\" in response_a or \"Error\" in response_b:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    judgment = await evaluator.evaluate_response_quality(\n",
    "                        query, response_a, response_b\n",
    "                    )\n",
    "                    \n",
    "                    # Convertir juicio a score ELO\n",
    "                    if judgment == \"A\":\n",
    "                        result = 1.0\n",
    "                    elif judgment == \"B\":\n",
    "                        result = 0.0\n",
    "                    else:  # EMPATE\n",
    "                        result = 0.5\n",
    "                    \n",
    "                    elo_system.update_ratings(config_a, config_b, result)\n",
    "                    total_comparisons += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error en evaluación: {e}\")\n",
    "    \n",
    "    print(f\"\\n✅ Evaluación completada. Total de comparaciones: {total_comparisons}\")\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(\"\\n🏆 RESULTADOS FINALES:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    leaderboard = elo_system.get_leaderboard()\n",
    "    for rank, (config_name, rating) in enumerate(leaderboard, 1):\n",
    "        print(f\"{rank}. {config_name}: {rating:.1f} ELO\")\n",
    "    \n",
    "    return elo_system, all_responses\n",
    "\n",
    "# Ejemplo de configuraciones para probar\n",
    "configurations = {\n",
    "    \"RAG_Standard\": {\n",
    "        \"k\": 5,\n",
    "        \"system_prompt\": \"\"\"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. \n",
    "        Tu tarea es analizar el contexto proporcionado y responder de manera precisa y concisa.\"\"\"\n",
    "    },\n",
    "    \"RAG_Detailed\": {\n",
    "        \"k\": 7,\n",
    "        \"system_prompt\": \"\"\"Eres un experto en derecho que analiza fallos judiciales. Proporciona respuestas detalladas, \n",
    "        cita las fuentes específicas cuando sea posible, y explica el razonamiento jurídico detrás de las decisiones.\"\"\"\n",
    "    },\n",
    "    \"RAG_Concise\": {\n",
    "        \"k\": 3,\n",
    "        \"system_prompt\": \"\"\"Eres un asistente legal que proporciona respuestas concisas y directas sobre fallos judiciales. \n",
    "        Enfócate en los puntos clave sin información redundante.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Queries de prueba (agregar más según tus casos de uso)\n",
    "test_queries = [\n",
    "    \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS -  Expte. Nº 8142\",\n",
    "    \"¿Cuáles son los fundamentos principales en casos de cobro de pesos?\",\n",
    "    \"¿Qué criterios se usan para determinar la responsabilidad en casos civiles?\",\n",
    "    # Agregar más queries relevantes a tu dominio\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2128856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Iniciando evaluación ELO...\n",
      "📝 Generando respuestas para configuración: RAG_Standard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando RAG_Standard: 100%|██████████| 3/3 [00:09<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Generando respuestas para configuración: RAG_Detailed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando RAG_Detailed: 100%|██████████| 3/3 [00:44<00:00, 14.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Generando respuestas para configuración: RAG_Concise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando RAG_Concise: 100%|██████████| 3/3 [00:08<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚔️ Realizando comparaciones ELO...\n",
      "\n",
      "🥊 RAG_Standard vs RAG_Detailed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparando: 100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🥊 RAG_Standard vs RAG_Concise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparando: 100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🥊 RAG_Detailed vs RAG_Concise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparando: 100%|██████████| 3/3 [00:01<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Evaluación completada. Total de comparaciones: 9\n",
      "\n",
      "🏆 RESULTADOS FINALES:\n",
      "==================================================\n",
      "1. RAG_Detailed: 1579.4 ELO\n",
      "2. RAG_Standard: 1479.0 ELO\n",
      "3. RAG_Concise: 1441.6 ELO\n",
      "\n",
      "📊 ANÁLISIS DETALLADO:\n",
      "==================================================\n",
      "Total de enfrentamientos: 9\n",
      "RAG_Standard: 2W-4L-0T (WR: 33.3%)\n",
      "RAG_Detailed: 6W-0L-0T (WR: 100.0%)\n",
      "RAG_Concise: 1W-5L-0T (WR: 16.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar evaluación ELO\n",
    "elo_results, response_cache = await run_elo_evaluation(test_queries, configurations)\n",
    "\n",
    "# Análisis adicional\n",
    "print(\"\\n📊 ANÁLISIS DETALLADO:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Historial de matches\n",
    "matches_df = pd.DataFrame(elo_results.match_history)\n",
    "print(f\"Total de enfrentamientos: {len(matches_df)}\")\n",
    "\n",
    "# Estadísticas por configuración\n",
    "for config_name in configurations.keys():\n",
    "    wins = len(matches_df[\n",
    "        ((matches_df['player_a'] == config_name) & (matches_df['result'] == 1.0)) |\n",
    "        ((matches_df['player_b'] == config_name) & (matches_df['result'] == 0.0))\n",
    "    ])\n",
    "    losses = len(matches_df[\n",
    "        ((matches_df['player_a'] == config_name) & (matches_df['result'] == 0.0)) |\n",
    "        ((matches_df['player_b'] == config_name) & (matches_df['result'] == 1.0))\n",
    "    ])\n",
    "    ties = len(matches_df[\n",
    "        ((matches_df['player_a'] == config_name) | (matches_df['player_b'] == config_name)) &\n",
    "        (matches_df['result'] == 0.5)\n",
    "    ])\n",
    "    \n",
    "    total_games = wins + losses + ties\n",
    "    if total_games > 0:\n",
    "        win_rate = wins / total_games * 100\n",
    "        print(f\"{config_name}: {wins}W-{losses}L-{ties}T (WR: {win_rate:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
