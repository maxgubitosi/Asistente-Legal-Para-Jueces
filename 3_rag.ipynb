{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b29cf294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, glob\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from IPython.display import display, Markdown\n",
    "import asyncio\n",
    "from openai import AsyncAzureOpenAI\n",
    "from configs.credentials_config import API_KEY, ENDPOINT, MODEL, DEPLOYMENT, EMBEDDINGS_API_KEY, EMBEDDINGS_ENDPOINT, EMBEDDINGS_VERSION, EMBEDDINGS_DEPLOYMENT # Crear archivo credentials_config.py con las credenciales de Azure OpenAI siguiendo el template\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from embeddings_wrapper import LangchainSentenceTransformer, AzureOpenAIEmbedder\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, ValidationError, Field\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15491519",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORSTORE_PATH = \"datasets/fallos_vectorstore_ada-002\"\n",
    "EMBEDDINGS_OPTION = \"azure_openai\" # \"langchain\" or \"azure_openai\"\n",
    "EMBEDDINGS_MODEL = \"mixedbread-ai/mxbai-embed-large-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba5e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de vectores en FAISS index: 4918\n",
      "Total de Document en docstore: 4918\n",
      "\n",
      "--- Primeros 5 Documentos ---\n",
      "ID: 6c42f9cd-a447-40c4-b3c8-cc7b383a4a69\n",
      "Texto (fragmento): '\"URBANOTEC S.A. S/ QUIEBRA\" - Expte. Nº 8985'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 3d97289c-d85d-4a48-9c57-e9340a4457a5\n",
      "Texto (fragmento): 'En la ciudad de Paraná, capital de la provincia de Entre Ríos, a los veinticinco días del mes de mar'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 0dc1a4e6-b40c-4b06-b020-1380f459886d\n",
      "Texto (fragmento): '1.- La sentencia de Camara que viene recurrida La sentencia de la Cámara de Apelaciones Sala Primera'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: ea826322-316b-4b29-a862-28370371fe45\n",
      "Texto (fragmento): 'En consecuencia redujo los honorarios de los letrados Angelini y Bargas a la suma de pesos quiniento'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 853f57c5-2dfb-4d1e-9ea2-bd847ffd569f\n",
      "Texto (fragmento): 'Para así decidir la Cámara, luego de establecer los agravios de los recurrentes, sostuvo que la cues'…\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "\n",
      "=== Estadísticas generales ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total fallos únicos</th>\n",
       "      <th>Total chunks</th>\n",
       "      <th>Secciones únicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total fallos únicos  Total chunks  Secciones únicas\n",
       "0                    0          4918                 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chunks por fuente (fallo) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuente</th>\n",
       "      <th>n_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fuente, n_chunks]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chunks por sección ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seccion</th>\n",
       "      <th>n_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seccion, n_chunks]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IDEA DE COMO CARGAR VECTORSTORE: MODIFICAR EL ORIGINAL PARA QUE TENGA METADATOS PARA:\n",
    "# * fuente: nombre del fallo (ej. \"8104\")\n",
    "# * seccion: sección del fallo (ej. \"Antecedentes\", \"Fundamentos de Derecho\", etc.)\n",
    "\n",
    "# 1. Cargar el índice FAISS desde el disco\n",
    "db = FAISS.load_local(\n",
    "    VECTORSTORE_PATH,\n",
    "    embeddings=None,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 2. Cantidad total de vectores (# chunks) \n",
    "print(\"Total de vectores en FAISS index:\", db.index.ntotal)\n",
    "\n",
    "# 3. Revisar cuántos Document guarda el docstore\n",
    "docs_dict = db.docstore._dict\n",
    "print(\"Total de Document en docstore:\", len(docs_dict))\n",
    "\n",
    "# 4. Inspeccionar los primeros 5 Document para ver texto y metadata\n",
    "print(\"\\n--- Primeros 5 Documentos ---\")\n",
    "for i, (doc_id, doc) in enumerate(docs_dict.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(\"Texto (fragmento):\", repr(doc.page_content[:100]) + \"…\")\n",
    "    print(\"Metadatos:\", doc.metadata)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# 5. Convertir metadata a DataFrame para análisis completo\n",
    "records = []\n",
    "for doc in docs_dict.values():\n",
    "    # Si metadata estuviera vacío, aparecerán valores por defecto\n",
    "    records.append({\n",
    "        \"fuente\":  doc.metadata.get(\"fuente\", None),\n",
    "        \"seccion\": doc.metadata.get(\"seccion\", None),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 5.a. Número de fallos distintos y chunks\n",
    "print(\"\\n=== Estadísticas generales ===\")\n",
    "summary = pd.DataFrame({\n",
    "    \"Total fallos únicos\":  [df[\"fuente\"].nunique(dropna=True)],\n",
    "    \"Total chunks\":         [len(df)],\n",
    "    \"Secciones únicas\":     [df[\"seccion\"].nunique(dropna=True)],\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "# 5.b. Chunks por 'fuente'\n",
    "chunks_per_fallo = (\n",
    "    df.groupby(\"fuente\")\n",
    "      .size()\n",
    "      .reset_index(name=\"n_chunks\")\n",
    "      .sort_values(\"n_chunks\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== Chunks por fuente (fallo) ===\")\n",
    "display(chunks_per_fallo)\n",
    "\n",
    "# 5.c. Chunks por 'seccion'\n",
    "chunks_per_seccion = (\n",
    "    df.groupby(\"seccion\")\n",
    "      .size()\n",
    "      .reset_index(name=\"n_chunks\")\n",
    "      .sort_values(\"n_chunks\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== Chunks por sección ===\")\n",
    "display(chunks_per_seccion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "if EMBEDDINGS_OPTION == \"langchain\":\n",
    "    embedding_model = LangchainSentenceTransformer(model_name = EMBEDDINGS_MODEL)\n",
    "    \n",
    "elif EMBEDDINGS_OPTION == \"azure_openai\":\n",
    "    embedding_model = AzureOpenAIEmbedder(\n",
    "        deployment_name = EMBEDDINGS_DEPLOYMENT,\n",
    "        endpoint        = EMBEDDINGS_ENDPOINT,\n",
    "        api_key         = EMBEDDINGS_API_KEY,\n",
    "        api_version     = EMBEDDINGS_VERSION,\n",
    "    )\n",
    "\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"datasets/fallos_vectorstore_ada-002\", \n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "\n",
    "def create_context(query):\n",
    "    results = vectorstore.similarity_search(query, k=5)\n",
    "    # for i, doc in enumerate(results, 1):\n",
    "    #     print(f\"{i}. {doc.page_content.strip()}\\n\")\n",
    "    return results\n",
    "\n",
    "azure_client = AsyncAzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "async def get_response(query):\n",
    "    res = await azure_client.chat.completions.create(\n",
    "        model=DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. Tu tarea es analizar el contexto y responder de manera precisa y concisa.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"El contexto es: {create_context(query)}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fb59da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await get_response(\"Explicame el fallo que dice: TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS -  Expte. Nº 8142\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78f3381d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El fallo correspondiente al expediente \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\" se refiere a un proceso judicial en el cual Alcides Vicente Terenzano demanda a Marta Olga Landivar y a otro demandado por un cobro de pesos. \n",
       "\n",
       "El tribunal considera la solicitud de regulación de honorarios presentada el 7 de diciembre de 2023, relacionada con la actuación profesional en recursos de inaplicabilidad de ley que fueron resueltos en fechas anteriores (25 de junio de 2020 y 10 de abril de 2023). Para este proceso, se toma en cuenta la normativa arancelaria aplicable, citando varios artículos de la ley 7046 que regulan tales situaciones.\n",
       "\n",
       "En resumen, el fallo se centra en la regulación de honorarios por el trabajo realizado en los mencionados recursos, ajustándose a la legislación pertinente y la liquidación económica aprobada previamente."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "respuesta = response.choices[0].message.content\n",
    "display(Markdown(respuesta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
