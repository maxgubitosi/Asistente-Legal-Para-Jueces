{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29cf294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, glob\n",
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from IPython.display import display, Markdown\n",
    "import asyncio\n",
    "from openai import AsyncAzureOpenAI\n",
    "from configs.credentials_config import API_KEY, ENDPOINT, MODEL, DEPLOYMENT, EMBEDDINGS_API_KEY, EMBEDDINGS_ENDPOINT, EMBEDDINGS_VERSION, EMBEDDINGS_DEPLOYMENT # Crear archivo credentials_config.py con las credenciales de Azure OpenAI siguiendo el template\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from embeddings_wrapper import LangchainSentenceTransformer, AzureOpenAIEmbedder\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, ValidationError, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15491519",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORSTORE_PATH = \"datasets/fallos_vectorstore_ada-002\"\n",
    "EMBEDDINGS_OPTION = \"azure_openai\" # \"langchain\" or \"azure_openai\"\n",
    "EMBEDDINGS_MODEL = \"mixedbread-ai/mxbai-embed-large-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba5e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de vectores en FAISS index: 4918\n",
      "Total de Document en docstore: 4918\n",
      "\n",
      "--- Primeros 5 Documentos ---\n",
      "ID: 6c42f9cd-a447-40c4-b3c8-cc7b383a4a69\n",
      "Texto (fragmento): '\"URBANOTEC S.A. S/ QUIEBRA\" - Expte. N¬∫ 8985'‚Ä¶\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 3d97289c-d85d-4a48-9c57-e9340a4457a5\n",
      "Texto (fragmento): 'En la ciudad de Paran√°, capital de la provincia de Entre R√≠os, a los veinticinco d√≠as del mes de mar'‚Ä¶\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 0dc1a4e6-b40c-4b06-b020-1380f459886d\n",
      "Texto (fragmento): '1.- La sentencia de Camara que viene recurrida La sentencia de la C√°mara de Apelaciones Sala Primera'‚Ä¶\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: ea826322-316b-4b29-a862-28370371fe45\n",
      "Texto (fragmento): 'En consecuencia redujo los honorarios de los letrados Angelini y Bargas a la suma de pesos quiniento'‚Ä¶\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "ID: 853f57c5-2dfb-4d1e-9ea2-bd847ffd569f\n",
      "Texto (fragmento): 'Para as√≠ decidir la C√°mara, luego de establecer los agravios de los recurrentes, sostuvo que la cues'‚Ä¶\n",
      "Metadatos: {}\n",
      "----------------------------------------\n",
      "\n",
      "=== Estad√≠sticas generales ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total fallos √∫nicos</th>\n",
       "      <th>Total chunks</th>\n",
       "      <th>Secciones √∫nicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total fallos √∫nicos  Total chunks  Secciones √∫nicas\n",
       "0                    0          4918                 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chunks por fuente (fallo) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuente</th>\n",
       "      <th>n_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fuente, n_chunks]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Chunks por secci√≥n ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seccion</th>\n",
       "      <th>n_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seccion, n_chunks]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IDEA DE COMO CARGAR VECTORSTORE: MODIFICAR EL ORIGINAL PARA QUE TENGA METADATOS PARA:\n",
    "# * fuente: nombre del fallo (ej. \"8104\")\n",
    "# * seccion: secci√≥n del fallo (ej. \"Antecedentes\", \"Fundamentos de Derecho\", etc.)\n",
    "\n",
    "# 1. Cargar el √≠ndice FAISS desde el disco\n",
    "db = FAISS.load_local(\n",
    "    VECTORSTORE_PATH,\n",
    "    embeddings=None,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 2. Cantidad total de vectores (# chunks) \n",
    "print(\"Total de vectores en FAISS index:\", db.index.ntotal)\n",
    "\n",
    "# 3. Revisar cu√°ntos Document guarda el docstore\n",
    "docs_dict = db.docstore._dict\n",
    "print(\"Total de Document en docstore:\", len(docs_dict))\n",
    "\n",
    "# 4. Inspeccionar los primeros 5 Document para ver texto y metadata\n",
    "print(\"\\n--- Primeros 5 Documentos ---\")\n",
    "for i, (doc_id, doc) in enumerate(docs_dict.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(\"Texto (fragmento):\", repr(doc.page_content[:100]) + \"‚Ä¶\")\n",
    "    print(\"Metadatos:\", doc.metadata)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# 5. Convertir metadata a DataFrame para an√°lisis completo\n",
    "records = []\n",
    "for doc in docs_dict.values():\n",
    "    # Si metadata estuviera vac√≠o, aparecer√°n valores por defecto\n",
    "    records.append({\n",
    "        \"fuente\":  doc.metadata.get(\"fuente\", None),\n",
    "        \"seccion\": doc.metadata.get(\"seccion\", None),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 5.a. N√∫mero de fallos distintos y chunks\n",
    "print(\"\\n=== Estad√≠sticas generales ===\")\n",
    "summary = pd.DataFrame({\n",
    "    \"Total fallos √∫nicos\":  [df[\"fuente\"].nunique(dropna=True)],\n",
    "    \"Total chunks\":         [len(df)],\n",
    "    \"Secciones √∫nicas\":     [df[\"seccion\"].nunique(dropna=True)],\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "# 5.b. Chunks por 'fuente'\n",
    "chunks_per_fallo = (\n",
    "    df.groupby(\"fuente\")\n",
    "      .size()\n",
    "      .reset_index(name=\"n_chunks\")\n",
    "      .sort_values(\"n_chunks\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== Chunks por fuente (fallo) ===\")\n",
    "display(chunks_per_fallo)\n",
    "\n",
    "# 5.c. Chunks por 'seccion'\n",
    "chunks_per_seccion = (\n",
    "    df.groupby(\"seccion\")\n",
    "      .size()\n",
    "      .reset_index(name=\"n_chunks\")\n",
    "      .sort_values(\"n_chunks\", ascending=False)\n",
    ")\n",
    "print(\"\\n=== Chunks por secci√≥n ===\")\n",
    "display(chunks_per_seccion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "if EMBEDDINGS_OPTION == \"langchain\":\n",
    "    embedding_model = LangchainSentenceTransformer(model_name = EMBEDDINGS_MODEL)\n",
    "    \n",
    "elif EMBEDDINGS_OPTION == \"azure_openai\":\n",
    "    embedding_model = AzureOpenAIEmbedder(\n",
    "        deployment_name = EMBEDDINGS_DEPLOYMENT,\n",
    "        endpoint        = EMBEDDINGS_ENDPOINT,\n",
    "        api_key         = EMBEDDINGS_API_KEY,\n",
    "        api_version     = EMBEDDINGS_VERSION,\n",
    "    )\n",
    "\n",
    "\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"datasets/fallos_vectorstore_ada-002\", \n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "\n",
    "def create_context(query):\n",
    "    results = vectorstore.similarity_search(query, k=5)\n",
    "    # for i, doc in enumerate(results, 1):\n",
    "    #     print(f\"{i}. {doc.page_content.strip()}\\n\")\n",
    "    return results\n",
    "\n",
    "azure_client = AsyncAzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "async def get_response(query):\n",
    "    res = await azure_client.chat.completions.create(\n",
    "        model=DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. Tu tarea es analizar el contexto y responder de manera precisa y concisa.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"El contexto es: {create_context(query)}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fb59da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await get_response(\"Explicame el fallo que dice: TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS -  Expte. N¬∫ 8142\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78f3381d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El fallo correspondiente al expediente \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\" se refiere a un proceso judicial en el cual Alcides Vicente Terenzano demanda a Marta Olga Landivar y a otro demandado por un cobro de pesos. \n",
       "\n",
       "El tribunal considera la solicitud de regulaci√≥n de honorarios presentada el 7 de diciembre de 2023, relacionada con la actuaci√≥n profesional en recursos de inaplicabilidad de ley que fueron resueltos en fechas anteriores (25 de junio de 2020 y 10 de abril de 2023). Para este proceso, se toma en cuenta la normativa arancelaria aplicable, citando varios art√≠culos de la ley 7046 que regulan tales situaciones.\n",
       "\n",
       "En resumen, el fallo se centra en la regulaci√≥n de honorarios por el trabajo realizado en los mencionados recursos, ajust√°ndose a la legislaci√≥n pertinente y la liquidaci√≥n econ√≥mica aprobada previamente."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "respuesta = response.choices[0].message.content\n",
    "display(Markdown(respuesta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c33d674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Consulta: TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\n",
      "================================================================================\n",
      "\n",
      "üìä Top 5 documentos m√°s similares:\n",
      "\n",
      "üèÜ Resultado #1 - Score: 0.1322\n",
      "üìÅ Fuente: N/A\n",
      "üìã Secci√≥n: N/A\n",
      "üìÑ Contenido: \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\"- Expte. N¬∫ 8142.\n",
      "PARAN√Å, 5 de febrero de 2024....\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ Resultado #2 - Score: 0.2176\n",
      "üìÅ Fuente: N/A\n",
      "üìã Secci√≥n: N/A\n",
      "üìÑ Contenido: Que los autos \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\" - Expte. N¬∫ 8142, vienen a consideraci√≥n de este Tribunal en virtud de la solicitud de regulaci√≥n de honorarios de fecha 7/12/2023, por la actuaci√≥n profesional en los recursos de inaplicabilidad de...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ Resultado #3 - Score: 0.2483\n",
      "üìÅ Fuente: N/A\n",
      "üìã Secci√≥n: N/A\n",
      "üìÑ Contenido: \"P√âREZ, Eusebio Antonio C/ ZAMPEDRI, Adri√°n Edgardo S/ ORDINARIO ACCION REIVINDICATORIA\"- Expte. N¬∫ 9111\"...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ Resultado #4 - Score: 0.2490\n",
      "üìÅ Fuente: N/A\n",
      "üìã Secci√≥n: N/A\n",
      "üìÑ Contenido: \"GIOVANARDI DE GRAZIANO, MARTA GRACIELA C/ WARNER, VANINA Y OTRO ORDINARIO- S/ EJECUCION DE SENTENCIA (Promovida parcialmente contra Alcides Marcelo L√ìPEZ - Expte. N¬∫ 10120)\" - Expte. N¬∫ 8543.\n",
      "PARAN√Å, 21 de octubre de 2024....\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ Resultado #5 - Score: 0.2570\n",
      "üìÅ Fuente: N/A\n",
      "üìã Secci√≥n: N/A\n",
      "üìÑ Contenido: \"CORBETTO RODOLFO LUIS C VERCESI CARLOS UBALDO S ORDINARIO ACCION REIVINDICATORIA S/ QUEJA (INTERPUESTA POR LA DRA MARIA AMELIA ANGEROSA DE CESPEDES)\" - Expte.\n",
      "N¬∞ 9158 PARANA, 7 de noviembre de 2024....\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyze_similarity_results(query, k=5):\n",
    "    \"\"\"\n",
    "    Analiza y muestra los resultados de similitud para una consulta\n",
    "    \"\"\"\n",
    "    print(f\"üîç Consulta: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Obtener resultados con scores de similitud\n",
    "    if hasattr(vectorstore, 'similarity_search_with_score'):\n",
    "        results_with_scores = vectorstore.similarity_search_with_score(query, k=k)\n",
    "        \n",
    "        print(f\"\\nüìä Top {k} documentos m√°s similares:\\n\")\n",
    "        \n",
    "        for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "            print(f\"üèÜ Resultado #{i} - Score: {score:.4f}\")\n",
    "            print(f\"üìÅ Fuente: {doc.metadata.get('fuente', 'N/A')}\")\n",
    "            print(f\"üìã Secci√≥n: {doc.metadata.get('seccion', 'N/A')}\")\n",
    "            print(f\"üìÑ Contenido: {doc.page_content[:300]}...\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        return results_with_scores\n",
    "    else:\n",
    "        # Fallback si no tiene similarity_search_with_score\n",
    "        results = vectorstore.similarity_search(query, k=k)\n",
    "        \n",
    "        print(f\"\\nüìä Top {k} documentos m√°s similares:\\n\")\n",
    "        \n",
    "        for i, doc in enumerate(results, 1):\n",
    "            print(f\"üèÜ Resultado #{i}\")\n",
    "            print(f\"üìÅ Fuente: {doc.metadata.get('fuente', 'N/A')}\")\n",
    "            print(f\"üìã Secci√≥n: {doc.metadata.get('seccion', 'N/A')}\")\n",
    "            print(f\"üìÑ Contenido: {doc.page_content[:300]}...\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "        return results\n",
    "\n",
    "# Ejemplo de uso\n",
    "query_test = \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS\"\n",
    "similarity_results = analyze_similarity_results(query_test, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e66033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_with_metadata(query, k=5):\n",
    "    \"\"\"\n",
    "    Crea contexto incluyendo metadatos para mejor trazabilidad\n",
    "    \"\"\"\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    \n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        fuente = doc.metadata.get('fuente', 'N/A')\n",
    "        seccion = doc.metadata.get('seccion', 'N/A')\n",
    "        \n",
    "        context_part = f\"\"\"\n",
    "Documento {i}:\n",
    "Fuente: {fuente}\n",
    "Secci√≥n: {seccion}\n",
    "Contenido: {doc.page_content.strip()}\n",
    "\"\"\"\n",
    "        context_parts.append(context_part)\n",
    "    \n",
    "    return \"\\n\".join(context_parts), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1262bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n para evaluaci√≥n ELO\n",
    "class RAGEvaluator:\n",
    "    def __init__(self, vectorstore, azure_client, deployment):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.azure_client = azure_client\n",
    "        self.deployment = deployment\n",
    "        \n",
    "    async def get_rag_response(self, query, k=5, system_prompt=None):\n",
    "        \"\"\"\n",
    "        Obtiene respuesta RAG con contexto recuperado\n",
    "        \"\"\"\n",
    "        context, retrieved_docs = create_context_with_metadata(query, k=k)\n",
    "        \n",
    "        if system_prompt is None:\n",
    "            system_prompt = \"\"\"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. \n",
    "            Tu tarea es analizar el contexto proporcionado y responder de manera precisa y concisa, citando las fuentes cuando sea relevante.\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"system\", \"content\": f\"Contexto de documentos relevantes:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        \n",
    "        response = await self.azure_client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=messages,\n",
    "            temperature=0.1  # Baja temperatura para consistencia\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'response': response.choices[0].message.content,\n",
    "            'retrieved_docs': retrieved_docs,\n",
    "            'context': context\n",
    "        }\n",
    "    \n",
    "    async def evaluate_response_quality(self, query, response_a, response_b):\n",
    "        \"\"\"\n",
    "        Eval√∫a qu√© respuesta es mejor usando el modelo como juez\n",
    "        \"\"\"\n",
    "        evaluation_prompt = f\"\"\"\n",
    "Eres un juez experto evaluando respuestas de un sistema de preguntas y respuestas sobre fallos judiciales.\n",
    "\n",
    "Pregunta: {query}\n",
    "\n",
    "Respuesta A: {response_a}\n",
    "\n",
    "Respuesta B: {response_b}\n",
    "\n",
    "Eval√∫a qu√© respuesta es mejor considerando:\n",
    "1. Precisi√≥n factual\n",
    "2. Relevancia al caso espec√≠fico\n",
    "3. Claridad y estructura\n",
    "4. Uso apropiado del contexto legal\n",
    "\n",
    "Responde √∫nicamente con: \"A\", \"B\", o \"EMPATE\"\n",
    "\"\"\"\n",
    "        \n",
    "        response = await self.azure_client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=[{\"role\": \"user\", \"content\": evaluation_prompt}],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content.strip().upper()\n",
    "        return result if result in [\"A\", \"B\", \"EMPATE\"] else \"EMPATE\"\n",
    "\n",
    "# Crear evaluador\n",
    "evaluator = RAGEvaluator(vectorstore, azure_client, DEPLOYMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6e6fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class ELOSystem:\n",
    "    def __init__(self, k_factor=32, initial_rating=1500):\n",
    "        self.k_factor = k_factor\n",
    "        self.initial_rating = initial_rating\n",
    "        self.ratings = defaultdict(lambda: initial_rating)\n",
    "        self.match_history = []\n",
    "    \n",
    "    def expected_score(self, rating_a, rating_b):\n",
    "        \"\"\"Calcula la probabilidad esperada de que A gane contra B\"\"\"\n",
    "        return 1 / (1 + 10**((rating_b - rating_a) / 400))\n",
    "    \n",
    "    def update_ratings(self, player_a, player_b, result):\n",
    "        \"\"\"\n",
    "        Actualiza ratings basado en el resultado\n",
    "        result: 1 si A gana, 0 si B gana, 0.5 si empate\n",
    "        \"\"\"\n",
    "        rating_a = self.ratings[player_a]\n",
    "        rating_b = self.ratings[player_b]\n",
    "        \n",
    "        expected_a = self.expected_score(rating_a, rating_b)\n",
    "        expected_b = self.expected_score(rating_b, rating_a)\n",
    "        \n",
    "        new_rating_a = rating_a + self.k_factor * (result - expected_a)\n",
    "        new_rating_b = rating_b + self.k_factor * ((1 - result) - expected_b)\n",
    "        \n",
    "        self.ratings[player_a] = new_rating_a\n",
    "        self.ratings[player_b] = new_rating_b\n",
    "        \n",
    "        # Guardar historial\n",
    "        self.match_history.append({\n",
    "            'player_a': player_a,\n",
    "            'player_b': player_b,\n",
    "            'result': result,\n",
    "            'rating_a_before': rating_a,\n",
    "            'rating_b_before': rating_b,\n",
    "            'rating_a_after': new_rating_a,\n",
    "            'rating_b_after': new_rating_b\n",
    "        })\n",
    "        \n",
    "        return new_rating_a, new_rating_b\n",
    "    \n",
    "    def get_leaderboard(self):\n",
    "        \"\"\"Retorna leaderboard ordenado por rating\"\"\"\n",
    "        return sorted(self.ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Inicializar sistema ELO\n",
    "elo_system = ELOSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a475d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_elo_evaluation(queries, configurations):\n",
    "    \"\"\"\n",
    "    Ejecuta evaluaci√≥n ELO entre diferentes configuraciones de RAG\n",
    "    \n",
    "    queries: Lista de preguntas de prueba\n",
    "    configurations: Dict con diferentes configuraciones {name: config_dict}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéØ Iniciando evaluaci√≥n ELO...\")\n",
    "    \n",
    "    # Generar todas las respuestas\n",
    "    all_responses = {}\n",
    "    \n",
    "    for config_name, config in configurations.items():\n",
    "        print(f\"üìù Generando respuestas para configuraci√≥n: {config_name}\")\n",
    "        all_responses[config_name] = {}\n",
    "        \n",
    "        for query in tqdm(queries, desc=f\"Procesando {config_name}\"):\n",
    "            try:\n",
    "                result = await evaluator.get_rag_response(\n",
    "                    query, \n",
    "                    k=config.get('k', 5),\n",
    "                    system_prompt=config.get('system_prompt', None)\n",
    "                )\n",
    "                all_responses[config_name][query] = result['response']\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error en {config_name} para query '{query[:50]}...': {e}\")\n",
    "                all_responses[config_name][query] = \"Error en generaci√≥n\"\n",
    "    \n",
    "    # Realizar comparaciones ELO\n",
    "    print(\"\\n‚öîÔ∏è Realizando comparaciones ELO...\")\n",
    "    \n",
    "    config_names = list(configurations.keys())\n",
    "    total_comparisons = 0\n",
    "    \n",
    "    for i, config_a in enumerate(config_names):\n",
    "        for j, config_b in enumerate(config_names[i+1:], i+1):\n",
    "            print(f\"\\nü•ä {config_a} vs {config_b}\")\n",
    "            \n",
    "            for query in tqdm(queries, desc=\"Comparando\"):\n",
    "                response_a = all_responses[config_a][query]\n",
    "                response_b = all_responses[config_b][query]\n",
    "                \n",
    "                if \"Error\" in response_a or \"Error\" in response_b:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    judgment = await evaluator.evaluate_response_quality(\n",
    "                        query, response_a, response_b\n",
    "                    )\n",
    "                    \n",
    "                    # Convertir juicio a score ELO\n",
    "                    if judgment == \"A\":\n",
    "                        result = 1.0\n",
    "                    elif judgment == \"B\":\n",
    "                        result = 0.0\n",
    "                    else:  # EMPATE\n",
    "                        result = 0.5\n",
    "                    \n",
    "                    elo_system.update_ratings(config_a, config_b, result)\n",
    "                    total_comparisons += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error en evaluaci√≥n: {e}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Evaluaci√≥n completada. Total de comparaciones: {total_comparisons}\")\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(\"\\nüèÜ RESULTADOS FINALES:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    leaderboard = elo_system.get_leaderboard()\n",
    "    for rank, (config_name, rating) in enumerate(leaderboard, 1):\n",
    "        print(f\"{rank}. {config_name}: {rating:.1f} ELO\")\n",
    "    \n",
    "    return elo_system, all_responses\n",
    "\n",
    "# Ejemplo de configuraciones para probar\n",
    "configurations = {\n",
    "    \"RAG_Standard\": {\n",
    "        \"k\": 5,\n",
    "        \"system_prompt\": \"\"\"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. \n",
    "        Tu tarea es analizar el contexto proporcionado y responder de manera precisa y concisa.\"\"\"\n",
    "    },\n",
    "    \"RAG_Detailed\": {\n",
    "        \"k\": 7,\n",
    "        \"system_prompt\": \"\"\"Eres un experto en derecho que analiza fallos judiciales. Proporciona respuestas detalladas, \n",
    "        cita las fuentes espec√≠ficas cuando sea posible, y explica el razonamiento jur√≠dico detr√°s de las decisiones.\"\"\"\n",
    "    },\n",
    "    \"RAG_Concise\": {\n",
    "        \"k\": 3,\n",
    "        \"system_prompt\": \"\"\"Eres un asistente legal que proporciona respuestas concisas y directas sobre fallos judiciales. \n",
    "        Enf√≥cate en los puntos clave sin informaci√≥n redundante.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Queries de prueba (agregar m√°s seg√∫n tus casos de uso)\n",
    "test_queries = [\n",
    "    \"TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS -  Expte. N¬∫ 8142\",\n",
    "    \"¬øCu√°les son los fundamentos principales en casos de cobro de pesos?\",\n",
    "    \"¬øQu√© criterios se usan para determinar la responsabilidad en casos civiles?\",\n",
    "    # Agregar m√°s queries relevantes a tu dominio\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2128856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Iniciando evaluaci√≥n ELO...\n",
      "üìù Generando respuestas para configuraci√≥n: RAG_Standard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando RAG_Standard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:09<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Generando respuestas para configuraci√≥n: RAG_Detailed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando RAG_Detailed: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:44<00:00, 14.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Generando respuestas para configuraci√≥n: RAG_Concise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando RAG_Concise: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:08<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öîÔ∏è Realizando comparaciones ELO...\n",
      "\n",
      "ü•ä RAG_Standard vs RAG_Detailed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü•ä RAG_Standard vs RAG_Concise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü•ä RAG_Detailed vs RAG_Concise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Evaluaci√≥n completada. Total de comparaciones: 9\n",
      "\n",
      "üèÜ RESULTADOS FINALES:\n",
      "==================================================\n",
      "1. RAG_Detailed: 1579.4 ELO\n",
      "2. RAG_Standard: 1479.0 ELO\n",
      "3. RAG_Concise: 1441.6 ELO\n",
      "\n",
      "üìä AN√ÅLISIS DETALLADO:\n",
      "==================================================\n",
      "Total de enfrentamientos: 9\n",
      "RAG_Standard: 2W-4L-0T (WR: 33.3%)\n",
      "RAG_Detailed: 6W-0L-0T (WR: 100.0%)\n",
      "RAG_Concise: 1W-5L-0T (WR: 16.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar evaluaci√≥n ELO\n",
    "elo_results, response_cache = await run_elo_evaluation(test_queries, configurations)\n",
    "\n",
    "# An√°lisis adicional\n",
    "print(\"\\nüìä AN√ÅLISIS DETALLADO:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Historial de matches\n",
    "matches_df = pd.DataFrame(elo_results.match_history)\n",
    "print(f\"Total de enfrentamientos: {len(matches_df)}\")\n",
    "\n",
    "# Estad√≠sticas por configuraci√≥n\n",
    "for config_name in configurations.keys():\n",
    "    wins = len(matches_df[\n",
    "        ((matches_df['player_a'] == config_name) & (matches_df['result'] == 1.0)) |\n",
    "        ((matches_df['player_b'] == config_name) & (matches_df['result'] == 0.0))\n",
    "    ])\n",
    "    losses = len(matches_df[\n",
    "        ((matches_df['player_a'] == config_name) & (matches_df['result'] == 0.0)) |\n",
    "        ((matches_df['player_b'] == config_name) & (matches_df['result'] == 1.0))\n",
    "    ])\n",
    "    ties = len(matches_df[\n",
    "        ((matches_df['player_a'] == config_name) | (matches_df['player_b'] == config_name)) &\n",
    "        (matches_df['result'] == 0.5)\n",
    "    ])\n",
    "    \n",
    "    total_games = wins + losses + ties\n",
    "    if total_games > 0:\n",
    "        win_rate = wins / total_games * 100\n",
    "        print(f\"{config_name}: {wins}W-{losses}L-{ties}T (WR: {win_rate:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
