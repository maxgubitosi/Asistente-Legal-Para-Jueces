{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in /Users/maxi/miniforge3/envs/nlp/lib/python3.11/site-packages (from faiss-cpu) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain_community --quiet\n",
    "!pip install pypdf --quiet\n",
    "!pip install instructor --quiet\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, glob\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from embeddings_wrapper import LangchainSentenceTransformer\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, ValidationError, Field\n",
    "from openai import AsyncAzureOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionar parámetros en la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.maxi_config import API_KEY, ENDPOINT, MODEL, DEPLOYMENT # Cambiar 'maxi_config' por la que corresponda\n",
    "\n",
    "JSONS_FOLDER = \"datasets/fallos_json\"\n",
    "OUTPUT_FOLDER = \"datasets/fallos_vectorstore\"\n",
    "\n",
    "EMBEDDINGS_MODEL = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "CHUNK_SIZE = 1024\n",
    "CHUNK_OVERLAP = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Cargando y dividiendo los fallos JSON...\n",
      "[INFO] Total de fragmentos generados: 253\n",
      "[INFO] Generando embeddings...\n",
      "[INFO] Filtering 253 chunks...\n",
      "[INFO] Embedding 253 clean chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 8/8 [01:34<00:00, 11.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# Lee múltiples fallos en JSON\n",
    "print(\"[INFO] Cargando y dividiendo los fallos JSON...\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for path in glob.glob(os.path.join(JSONS_FOLDER, \"*.json\")):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        fallos = json.load(f)          # cada archivo es un array con 1 fallo\n",
    "\n",
    "    for fallo in fallos:\n",
    "        contenido = fallo.get(\"CONTENIDO\", {})\n",
    "        for seccion, parrafos in contenido.items():\n",
    "            texto = \"\\n\".join(parrafos)            # solo esa sección\n",
    "            for frag in splitter.split_text(texto):\n",
    "                chunks.append(\n",
    "                    Document(\n",
    "                        page_content = frag,\n",
    "                        metadata = {\n",
    "                            \"seccion\": seccion,\n",
    "                            \"fuente\" : os.path.basename(path)\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "print(f\"[INFO] Total de fragmentos generados: {len(chunks)}\")\n",
    "\n",
    "# --- Embeddings y FAISS ---\n",
    "print(\"[INFO] Generando embeddings...\")\n",
    "embedding_model = LangchainSentenceTransformer()\n",
    "texts, embeddings = embedding_model.embed_documents(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "text_embedding_pairs = list(zip(texts, embeddings))\n",
    "vectorstore = FAISS.from_embeddings(text_embedding_pairs, embedding_model)\n",
    "vectorstore.save_local(\"datasets/fallos_vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(query):\n",
    "    results = vectorstore.similarity_search(query, k=5)\n",
    "    # for i, doc in enumerate(results, 1):\n",
    "    #     print(f\"{i}. {doc.page_content.strip()}\\n\")\n",
    "    return results\n",
    "\n",
    "azure_client = AsyncAzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=ENDPOINT,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "async def get_response(query):\n",
    "    res = await azure_client.chat.completions.create(\n",
    "        model=DEPLOYMENT,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Sos un asistente judicial especializado en encontrar semejanzas entre fallos y responder preguntas sobre ellos. Tu tarea es analizar el contexto y responder de manera precisa y concisa.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"El contexto es: {create_context(query)}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await get_response(\"Explicame el fallo que dice: TERENZANO, ALCIDES VICENTE C/ LANDIVAR, MARTA OLGA Y OTRO S/ ORDINARIO COBRO DE PESOS -  Expte. Nº 8142\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El fallo mencionado se refiere a un caso judicial en el que Alcides Vicente Terenzano demanda a Marta Olga Landivar y a otro co-demandado en el marco de un \"ordinario cobro de pesos\". Este tipo de procedimiento generalmente se utiliza para reclamar el pago de deudas u obligaciones económicas.\\n\\nEn el contexto del expediente Nº 8142, se menciona específicamente una solicitud de regulación de honorarios por parte de los abogados involucrados en el caso, lo cual indica que ya hubo actuaciones profesionales previas relacionadas con el asunto. Se hace referencia a decisiones anteriores sobre recursos de inaplicabilidad de ley, lo que sugiere que ha habido un análisis sobre la aplicación de normas jurídicas en este caso, resueltas en fechas anteriores (25/6/2020 y 10/4/2023).\\n\\nAdemás, se hace alusión a la normativa arancelaria aplicable, destacando ciertos artículos de la ley 7046 que regulan cómo se deben establecer los honorarios de los abogados en estos casos. Esto sugiere una etapa en el proceso judicial relacionada con los costos y compensaciones por las actuaciones legales realizadas.\\n\\nEn resumen, el fallo en cuestión trata sobre un reclamo financiero, donde se regula la compensación por servicios legales en un contexto donde ya han sucedido actuaciones y resoluciones anteriores.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta = response.choices[0].message.content\n",
    "respuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El fallo mencionado se refiere a un caso judicial en el que Alcides Vicente Terenzano demanda a Marta Olga Landivar y a otro co-demandado en el marco de un \"ordinario cobro de pesos\". Este tipo de procedimiento generalmente se utiliza para reclamar el pago de deudas u obligaciones económicas.\n",
       "\n",
       "En el contexto del expediente Nº 8142, se menciona específicamente una solicitud de regulación de honorarios por parte de los abogados involucrados en el caso, lo cual indica que ya hubo actuaciones profesionales previas relacionadas con el asunto. Se hace referencia a decisiones anteriores sobre recursos de inaplicabilidad de ley, lo que sugiere que ha habido un análisis sobre la aplicación de normas jurídicas en este caso, resueltas en fechas anteriores (25/6/2020 y 10/4/2023).\n",
       "\n",
       "Además, se hace alusión a la normativa arancelaria aplicable, destacando ciertos artículos de la ley 7046 que regulan cómo se deben establecer los honorarios de los abogados en estos casos. Esto sugiere una etapa en el proceso judicial relacionada con los costos y compensaciones por las actuaciones legales realizadas.\n",
       "\n",
       "En resumen, el fallo en cuestión trata sobre un reclamo financiero, donde se regula la compensación por servicios legales en un contexto donde ya han sucedido actuaciones y resoluciones anteriores."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "display(Markdown(respuesta))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
